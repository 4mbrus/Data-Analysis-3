{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991f0550",
   "metadata": {},
   "source": [
    "### PART I: Probability prediction\n",
    "- Predict probabilities.\n",
    "- Look at cross-validated performance and pick your favorite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fec2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from statsmodels.tools.eval_measures import mse,rmse\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV, Lasso\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, brier_score_loss, roc_curve, auc, confusion_matrix, roc_auc_score\n",
    "import patsy\n",
    "from stargazer.stargazer import Stargazer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54199ddf",
   "metadata": {},
   "source": [
    "# PART I: Probability prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4966b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the clean dataset\n",
    "firms_df = pd.read_csv(\"bisnode_firms_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3625ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawvars = [\"curr_assets\", \"curr_liab\", \"extra_exp\", \"extra_inc\", \"extra_profit_loss\", \"fixed_assets\",\n",
    "              \"inc_bef_tax\", \"intang_assets\", \"inventories\", \"liq_assets\", \"material_exp\", \"personnel_exp\",\n",
    "              \"profit_loss_year\", \"sales\", \"share_eq\", \"subscribed_cap\"]\n",
    "\n",
    "qualityvars = [\"balsheet_flag\", \"balsheet_length\", \"balsheet_notfullyear\"]\n",
    "\n",
    "engvar = [\"total_assets_bs\", \"fixed_assets_bs\", \"liq_assets_bs\", \"curr_assets_bs\",\n",
    "            \"share_eq_bs\", \"subscribed_cap_bs\", \"intang_assets_bs\", \"extra_exp_pl\",\n",
    "            \"extra_inc_pl\", \"extra_profit_loss_pl\", \"inc_bef_tax_pl\", \"inventories_pl\",\n",
    "            \"material_exp_pl\", \"profit_loss_year_pl\", \"personnel_exp_pl\"]\n",
    "\n",
    "engvar2 = [\"extra_profit_loss_pl_quad\", \"inc_bef_tax_pl_quad\",\n",
    "             \"profit_loss_year_pl_quad\", \"share_eq_bs_quad\"]\n",
    "\n",
    "engvar3 = []\n",
    "for col in firms_df.columns:\n",
    "    if col.endswith('flag_low') or col.endswith('flag_high') or col.endswith('flag_error') or col.endswith('flag_zero'):\n",
    "        engvar3.append(col)\n",
    "\n",
    "#d1 =  [\"d1_sales_mil_log_mod\", \"d1_sales_mil_log_mod_sq\",\n",
    "         #\"flag_low_d1_sales_mil_log\", \"flag_high_d1_sales_mil_log\"] Data leak! Removed every d1 sales value from the code\n",
    "\n",
    "hr = [\"female\", \"ceo_age\", \"flag_high_ceo_age\", \"flag_low_ceo_age\",\n",
    "        \"flag_miss_ceo_age\", \"ceo_count\", \"labor_avg_mod\",\n",
    "        \"flag_miss_labor_avg\", \"foreign_management\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663b4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = rawvars + qualityvars + engvar + engvar2 + engvar3 + hr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6c93f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curr_assets            0\n",
       "curr_liab              0\n",
       "extra_exp              0\n",
       "extra_inc              0\n",
       "extra_profit_loss      0\n",
       "                      ..\n",
       "flag_miss_ceo_age      0\n",
       "ceo_count              0\n",
       "labor_avg_mod          0\n",
       "flag_miss_labor_avg    0\n",
       "foreign_management     0\n",
       "Length: 74, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[all_vars].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5f52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "firms_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c7095",
   "metadata": {},
   "source": [
    "### Dealing with categorical variables\n",
    "To avoide multicolinearity, we drop the first values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6b1a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>comp_id</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>amort</th>\n",
       "      <th>curr_assets</th>\n",
       "      <th>curr_liab</th>\n",
       "      <th>extra_exp</th>\n",
       "      <th>extra_inc</th>\n",
       "      <th>extra_profit_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_high_ceo_age</th>\n",
       "      <th>flag_miss_ceo_age</th>\n",
       "      <th>ceo_young</th>\n",
       "      <th>labor_avg_mod</th>\n",
       "      <th>flag_miss_labor_avg</th>\n",
       "      <th>sales_mil_log_sq</th>\n",
       "      <th>flag_low_d1_sales_mil_log</th>\n",
       "      <th>flag_high_d1_sales_mil_log</th>\n",
       "      <th>d1_sales_mil_log_mod</th>\n",
       "      <th>d1_sales_mil_log_mod_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>1002029.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>14255.555664</td>\n",
       "      <td>217103.703125</td>\n",
       "      <td>161174.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1.054824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.155013</td>\n",
       "      <td>1.334055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1011889.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>66125.929688</td>\n",
       "      <td>235114.812500</td>\n",
       "      <td>16555.554688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019109</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1014183.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>6970.370605</td>\n",
       "      <td>209562.968750</td>\n",
       "      <td>5703.703613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0</td>\n",
       "      <td>4.632597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.110044</td>\n",
       "      <td>0.012110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>1022796.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>503.703705</td>\n",
       "      <td>3859.259277</td>\n",
       "      <td>8114.814941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>9.971799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488146</td>\n",
       "      <td>0.238287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>1035705.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>244.444443</td>\n",
       "      <td>2392.592529</td>\n",
       "      <td>9733.333008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>14.500839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.079375</td>\n",
       "      <td>0.006300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    comp_id       begin         end         amort    curr_assets  \\\n",
       "0  2013  1002029.0  2013-01-01  2013-12-31  14255.555664  217103.703125   \n",
       "1  2013  1011889.0  2013-01-01  2013-12-31  66125.929688  235114.812500   \n",
       "2  2013  1014183.0  2013-01-01  2013-12-31   6970.370605  209562.968750   \n",
       "3  2013  1022796.0  2013-01-01  2013-12-31    503.703705    3859.259277   \n",
       "4  2013  1035705.0  2013-01-01  2013-12-31    244.444443    2392.592529   \n",
       "\n",
       "       curr_liab  extra_exp  extra_inc  extra_profit_loss  ...  \\\n",
       "0  161174.078125        0.0        0.0                0.0  ...   \n",
       "1   16555.554688        0.0        0.0                0.0  ...   \n",
       "2    5703.703613        0.0        0.0                0.0  ...   \n",
       "3    8114.814941        0.0        0.0                0.0  ...   \n",
       "4    9733.333008        0.0        0.0                0.0  ...   \n",
       "\n",
       "   flag_high_ceo_age  flag_miss_ceo_age  ceo_young  labor_avg_mod  \\\n",
       "0                  0                  0          1       0.437500   \n",
       "1                  0                  0          0       1.583333   \n",
       "2                  0                  0          0       0.819444   \n",
       "3                  0                  0          0       0.083333   \n",
       "4                  0                  0          0       0.222222   \n",
       "\n",
       "   flag_miss_labor_avg  sales_mil_log_sq  flag_low_d1_sales_mil_log  \\\n",
       "0                    0          1.054824                          0   \n",
       "1                    0          0.666460                          0   \n",
       "2                    0          4.632597                          0   \n",
       "3                    0          9.971799                          0   \n",
       "4                    0         14.500839                          0   \n",
       "\n",
       "   flag_high_d1_sales_mil_log  d1_sales_mil_log_mod  d1_sales_mil_log_mod_sq  \n",
       "0                           0             -1.155013                 1.334055  \n",
       "1                           0              0.019109                 0.000365  \n",
       "2                           0             -0.110044                 0.012110  \n",
       "3                           0              0.488146                 0.238287  \n",
       "4                           0             -0.079375                 0.006300  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09051331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ind2_cat\n",
       "26.0     735\n",
       "27.0     441\n",
       "28.0    1389\n",
       "29.0     179\n",
       "30.0     104\n",
       "33.0    1382\n",
       "55.0    1299\n",
       "56.0    8039\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[\"ind2_cat\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1810b18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urban_m\n",
       "1.0    4278\n",
       "2.0    3872\n",
       "3.0    5418\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[\"urban_m\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f83d539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_region_loc\n",
       "Central    7964\n",
       "East       3404\n",
       "West       2200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[\"m_region_loc\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e17643",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2_catmat = patsy.dmatrix(\"0 + C(ind2_cat, Treatment(reference=26))\", firms_df, return_type=\"dataframe\")\n",
    "m_region_locmat = patsy.dmatrix(\"0 + C(m_region_loc, Treatment(reference='Central'))\", firms_df, return_type=\"dataframe\")\n",
    "urban_mmat = patsy.dmatrix(\"0 + C(urban_m, Treatment(reference=1))\", firms_df, return_type=\"dataframe\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f26bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X1\n",
    "basevars = firms_df[[\"sales_mil_log\", \"sales_mil_log_sq\", \"profit_loss_year_pl\"]]\n",
    "X1 = pd.concat([basevars, ind2_catmat], axis=1)\n",
    "\n",
    "# Define X2\n",
    "X2additional_vars = firms_df[[\"fixed_assets_bs\", \"share_eq_bs\",\"curr_liab_bs\", \"curr_liab_bs_flag_high\", \\\n",
    "                          \"curr_liab_bs_flag_error\",  \"age\", \"foreign_management\"]]\n",
    "X2 = pd.concat([X1, X2additional_vars], axis=1)\n",
    "\n",
    "# Define X3\n",
    "firm = pd.concat([firms_df[[\"age\", \"age2\", \"new\"]], ind2_catmat, m_region_locmat, urban_mmat], axis=1)\n",
    "X3 = pd.concat([firms_df[[\"sales_mil_log\", \"sales_mil_log_sq\"] + engvar ], firm], axis=1)\n",
    "\n",
    "# Define X4\n",
    "X4 = pd.concat([firms_df[[\"sales_mil_log\", \"sales_mil_log_sq\"] + engvar \\\n",
    "                                 + engvar2 + engvar3 + hr + qualityvars], firm], axis=1)\n",
    "\n",
    "# Define X5\n",
    "\n",
    "#Creat matrix for interactions1 variables\n",
    "int1mat = patsy.dmatrix(\"0 + C(ind2_cat):age + C(ind2_cat):age2 \\\n",
    "                + C(ind2_cat):sales_mil_log + C(ind2_cat):ceo_age + C(ind2_cat):foreign_management \\\n",
    "                + C(ind2_cat):female + C(ind2_cat):C(urban_m) + C(ind2_cat):labor_avg_mod\", \n",
    "                        firms_df, return_type=\"dataframe\")\n",
    "\n",
    "#Drop first level to get k-1 dummies out of k categorical levels \n",
    "for col in int1mat.columns:\n",
    "    if col.startswith('C(ind2_cat)[26]') or col.endswith('C(urban_m)[1]'):\n",
    "        int1mat = int1mat.drop([col], axis=1)\n",
    "        \n",
    "#Creat matrix for interactions2 variables        \n",
    "int2mat = patsy.dmatrix(\"0 + sales_mil_log:age + sales_mil_log:female + sales_mil_log:profit_loss_year_pl \\\n",
    "                + sales_mil_log:foreign_management\", \n",
    "                        firms_df, return_type=\"dataframe\")\n",
    "\n",
    "X5 = pd.concat([X4, int1mat, int2mat], axis=1)\n",
    "\n",
    "# Define logitvars for LASSO\n",
    "logitvars = pd.concat([X4, int1mat, int2mat], axis=1)\n",
    "\n",
    "# Define rfvars for RF (no interactions, no modified features)\n",
    "rfvars  = pd.concat([firms_df[[\"sales_mil\"] + rawvars + hr + qualityvars], firm], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62833502",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2267173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "\n",
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    \n",
    "def create_coef_matrix(X, model):\n",
    "    coef_matrix = pd.concat(\n",
    "        [pd.DataFrame(X.columns),pd.DataFrame(model.coef_.flatten())], axis = 1\n",
    "    )\n",
    "    coef_matrix.columns = ['variable', 'coefficient']\n",
    "    coef_matrix.iloc[-1] = ['Intercept', model.intercept_.flatten()[0]]\n",
    "    return coef_matrix\n",
    "\n",
    "def cv_summary(lambdas, C_values, model):\n",
    "    d = {'lambdas': lambdas, \n",
    "         'C_values': C_values, \n",
    "         'mean_cv_score': model.scores_[1].mean(axis = 0)}\n",
    "    return(pd.DataFrame(data=d))\n",
    "\n",
    "\"\"\"def create_roc_plot(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    all_coords = pd.DataFrame({\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'thresholds': thresholds\n",
    "    })\n",
    "    \n",
    "    plot = ggplot(all_coords, aes(x = 'fpr', y = 'tpr')) \\\n",
    "        + geom_line(color=color[0], size = 0.7) \\\n",
    "        + geom_area(position = 'identity', fill = 'mediumaquamarine', alpha = 0.3) \\\n",
    "        + xlab(\"False Positive Rate (1-Specifity)\") \\\n",
    "        + ylab(\"True Positive Rate (Sensitivity)\") \\\n",
    "        + geom_abline(intercept = 0, slope = 1,  linetype = \"dotted\", color = \"black\") \\\n",
    "        + scale_y_continuous(limits = (0, 1), breaks = seq(0, 1, .1), expand = (0, 0.01)) \\\n",
    "        + scale_x_continuous(limits = (0, 1), breaks = seq(0, 1, .1), expand = (0.01, 0)) \\\n",
    "        + theme_bw()\n",
    "    return(plot)\n",
    "\"\"\"\n",
    "\n",
    "def create_roc_plot(y_true, y_pred): # this is pretty important!\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred) # on x false positive and on y true positive\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    # Plot ROC curve line\n",
    "    ax.plot(fpr, tpr, color='k', linewidth=0.7)\n",
    "    \n",
    "    # Fill area under curve\n",
    "    ax.fill_between(fpr, tpr, alpha=0.3, color='white')\n",
    "    \n",
    "    # Add diagonal dotted line\n",
    "    ax.plot([0, 1], [0, 1], linestyle=':', color='black')\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax.set_xlabel('False Positive Rate (1-Specificity)')\n",
    "    ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "    \n",
    "    # Set axis limits and ticks\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    \n",
    "    # Style similar to theme_bw()\n",
    "    ax.grid(True, linestyle='-', alpha=0.2)\n",
    "    ax.set_facecolor('white')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def sigmoid_array(x):\n",
    "    return(1 / (1 + np.exp(-x)))\n",
    "\n",
    "def generate_fold_prediction(model, X, fold, param_index):\n",
    "    fold_coef = model.coefs_paths_[1][fold,param_index,:]\n",
    "    return(sigmoid_array(np.dot(X, np.transpose(fold_coef)[:-1]) +  np.transpose(fold_coef)[-1]))\n",
    "\n",
    "\"\"\"def create_loss_plot(all_coords, optimal_threshold, curr_exp_loss):\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['loss'] = (all_coords_copy.false_pos*FP + all_coords_copy.false_neg*FN)/all_coords_copy.n\n",
    "    \n",
    "    t = optimal_threshold\n",
    "    l = curr_exp_loss\n",
    "    \n",
    "    plot = ggplot(all_coords_copy, aes(x = 'thresholds', y = 'loss')) + \\\n",
    "        geom_line(color=color[0], size=0.7) + \\\n",
    "        scale_x_continuous(breaks = seq(0, 1.1, by = 0.1)) + \\\n",
    "        coord_cartesian(xlim=(0,1))+ \\\n",
    "        geom_vline(xintercept = t , color = color[0] ) + \\\n",
    "        annotate(geom = \"text\", x = t - 0.01, y= max(all_coords_copy.loss) - 0.4,\n",
    "                 label=\"best threshold: \" + str(round(t,2)),\n",
    "                 colour=color[1], angle=90, size = 7) +\\\n",
    "        annotate(geom = \"text\", x = t + 0.06, y= l,\\\n",
    "                 label= str(round(l, 2)), size = 7) +\\\n",
    "        theme_bw()\n",
    "    return(plot)\"\"\"\n",
    "\n",
    "def create_loss_plot(all_coords, optimal_threshold, curr_exp_loss): # what is optimal threshold here?\n",
    "    # Create copy and calculate loss\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['loss'] = (all_coords_copy.false_pos*FP + all_coords_copy.false_neg*FN)/all_coords_copy.n\n",
    "    \n",
    "    t = optimal_threshold\n",
    "    l = curr_exp_loss\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    # Plot loss line\n",
    "    ax.plot(all_coords_copy['thresholds'], all_coords_copy['loss'], \n",
    "            color= 'k', linewidth=0.7)\n",
    "\n",
    "    # Add vertical line at optimal threshold\n",
    "    ax.axvline(x=t, color = 'k')\n",
    "\n",
    "    # Add annotations\n",
    "    ax.text(t - 0.04, max(all_coords_copy.loss) - 0.5,\n",
    "            f\"best threshold: {t:.2f}\", \n",
    "            color = 'k', \n",
    "            rotation=90, \n",
    "            fontsize = 9)\n",
    "    \n",
    "    ax.text(t + 0.06, l,\n",
    "            f\"{l:.2f}\",\n",
    "            fontsize = 9)\n",
    "\n",
    "    # Set x-axis ticks and limits\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "    # Style similar to theme_bw()\n",
    "    ax.grid(True, linestyle='-', alpha=0.2)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xlabel('threshold')\n",
    "    ax.set_ylabel('loss')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"def create_roc_plot_with_optimal(all_coords, optimal_threshold):\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['sp'] = all_coords_copy.true_neg/all_coords_copy.neg\n",
    "    all_coords_copy['se'] = all_coords_copy.true_pos/all_coords_copy.pos\n",
    "    \n",
    "    best_coords = all_coords_copy[all_coords_copy.thresholds == optimal_threshold]\n",
    "    sp = best_coords.sp.values[0]\n",
    "    se = best_coords.se.values[0]\n",
    "\n",
    "    plot = ggplot(all_coords_copy, aes(x = 'sp', y = 'se')) +\\\n",
    "        geom_line(color=color[0], size=0.7) +\\\n",
    "        scale_y_continuous(breaks = seq(0, 1.1, by = 0.1)) +\\\n",
    "        scale_x_reverse(breaks = seq(0, 1.1, by = 0.1)) +\\\n",
    "        geom_point(data = pd.DataFrame({'sp': [sp], 'se': [se]})) +\\\n",
    "        annotate(geom = \"text\", x = sp, y = se + 0.03,\n",
    "                 label = str(round(sp, 2)) + ', ' + str(round(se, 2)), size = 7) +\\\n",
    "        theme_bw()\n",
    "    return(plot)\n",
    "\"\"\"\n",
    "def create_roc_plot_with_optimal(all_coords, optimal_threshold):\n",
    "    # Create copy and calculate metrics\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['sp'] = all_coords_copy.true_neg/all_coords_copy.neg\n",
    "    all_coords_copy['se'] = all_coords_copy.true_pos/all_coords_copy.pos\n",
    "    \n",
    "    # Get optimal point\n",
    "    best_coords = all_coords_copy[all_coords_copy.thresholds == optimal_threshold]\n",
    "    sp = best_coords.sp.values[0]\n",
    "    se = best_coords.se.values[0]\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    ax.plot(all_coords_copy['sp'], all_coords_copy['se'],\n",
    "            color='k', linewidth=0.9)\n",
    "    \n",
    "    # Add optimal point\n",
    "    ax.scatter([sp], [se], color='k', s = 100)\n",
    "    \n",
    "    # Add text annotation\n",
    "    ax.text(sp, se + 0.03,\n",
    "            f\"{sp:.2f}, {se:.2f}\",\n",
    "            fontsize = 9,\n",
    "            ha='center')\n",
    "    ax.text(sp - 0.02, se - 0.18,\n",
    "            'specificity (TNR) \\n& sensitivity (TPR) \\nat the best threshold',\n",
    "            fontsize = 9,\n",
    "            ha='center'\n",
    "           )\n",
    "    \n",
    "    # Set axis ticks and limits\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_xlabel('specificity')\n",
    "    ax.set_ylabel('sensitivity')\n",
    "    \n",
    "    # Reverse x-axis\n",
    "    ax.set_xlim(1, 0)\n",
    "    \n",
    "    # Style similar to theme_bw()\n",
    "    ax.grid(True, linestyle='-', alpha=0.2)\n",
    "    ax.set_facecolor('white')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33affa09",
   "metadata": {},
   "source": [
    "### Setting up the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c268b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = firms_df[\"is_fast_growing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76268534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2318691037735849)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24865a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    firms_df,          \n",
    "    y,                 \n",
    "    test_size=0.2,     \n",
    "    random_state=42    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26074ffe",
   "metadata": {},
   "source": [
    "### OLS with Cross-Validation for X1:X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8b68ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross-Validation for: OLS_Model_X1\n",
      "Running Cross-Validation for: OLS_Model_X2\n",
      "Running Cross-Validation for: OLS_Model_X3\n",
      "Running Cross-Validation for: OLS_Model_X4\n",
      "Running Cross-Validation for: OLS_Model_X5\n",
      "Calculation complete.\n"
     ]
    }
   ],
   "source": [
    "model_specs = {\n",
    "    \"OLS_Model_X1\": X1,\n",
    "    \"OLS_Model_X2\": X2, \n",
    "    \"OLS_Model_X3\": X3,\n",
    "    \"OLS_Model_X4\": X4,\n",
    "    \"OLS_Model_X5\": X5\n",
    "}\n",
    "\n",
    "results = {name: {\n",
    "    'rmse_test': [], 'r2_test': [], 'pred_test_mean': [],\n",
    "    'rmse_train': [], 'r2_train': [], 'pred_train_mean': []\n",
    "} for name in model_specs}\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through each Model \n",
    "for model_name, X_data in model_specs.items():\n",
    "    \n",
    "    print(f\"Running Cross-Validation for: {model_name}\")\n",
    "    \n",
    "    # Inner Loop: K-Fold Split\n",
    "    for train_index, test_index in k.split(X_train):\n",
    "        \n",
    "        # Select data based on indices and add constant\n",
    "        X_train_fold = sm.add_constant(X_data.iloc[train_index])\n",
    "        X_test_fold = sm.add_constant(X_data.iloc[test_index])\n",
    "        \n",
    "        y_train_fold = y.iloc[train_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        # Fit OLS\n",
    "        model = sm.OLS(y_train_fold, X_train_fold).fit()\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_test = model.predict(X_test_fold)\n",
    "        y_pred_train = model.predict(X_train_fold)\n",
    "        \n",
    "        # --- Store Results into the Dictionary ---\n",
    "        \n",
    "        # Test Metrics\n",
    "        results[model_name]['rmse_test'].append(np.sqrt(mean_squared_error(y_test_fold, y_pred_test)))\n",
    "        results[model_name]['r2_test'].append(r2_score(y_test_fold, y_pred_test))\n",
    "        results[model_name]['pred_test_mean'].append(np.mean(y_pred_test))\n",
    "        \n",
    "        # Train Metrics\n",
    "        results[model_name]['rmse_train'].append(np.sqrt(mean_squared_error(y_train_fold, y_pred_train)))\n",
    "        results[model_name]['r2_train'].append(r2_score(y_train_fold, y_pred_train))\n",
    "        results[model_name]['pred_train_mean'].append(np.mean(y_pred_train))\n",
    "\n",
    "print(\"Calculation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b4d08a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg_RMSE_Test</th>\n",
       "      <th>Avg_R2_Test</th>\n",
       "      <th>Pred_Test_Mean</th>\n",
       "      <th>Avg_RMSE_Train</th>\n",
       "      <th>Avg_R2_Train</th>\n",
       "      <th>Pred_Train_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS_Model_X1</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLS_Model_X2</td>\n",
       "      <td>0.4039</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLS_Model_X3</td>\n",
       "      <td>0.3882</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.3862</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OLS_Model_X4</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.1793</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OLS_Model_X5</td>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Avg_RMSE_Test  Avg_R2_Test  Pred_Test_Mean  Avg_RMSE_Train  \\\n",
       "0  OLS_Model_X1         0.4160       0.0173          0.2283          0.4154   \n",
       "1  OLS_Model_X2         0.4039       0.0734          0.2284          0.4030   \n",
       "2  OLS_Model_X3         0.3882       0.1439          0.2285          0.3862   \n",
       "3  OLS_Model_X4         0.3913       0.1288          0.2275          0.3803   \n",
       "4  OLS_Model_X5         0.3899       0.1357          0.2276          0.3769   \n",
       "\n",
       "   Avg_R2_Train  Pred_Train_Mean  \n",
       "0        0.0208           0.2284  \n",
       "1        0.0785           0.2284  \n",
       "2        0.1537           0.2284  \n",
       "3        0.1793           0.2284  \n",
       "4        0.1939           0.2284  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_rows = []\n",
    "for name, metrics in results.items():\n",
    "    summary_rows.append({\n",
    "        'Model': name,\n",
    "        'Avg_RMSE_Test': np.mean(metrics['rmse_test']),\n",
    "        'Avg_R2_Test': np.mean(metrics['r2_test']),\n",
    "        'Pred_Test_Mean': np.mean(metrics['pred_test_mean']),\n",
    "        'Avg_RMSE_Train': np.mean(metrics['rmse_train']),\n",
    "        'Avg_R2_Train': np.mean(metrics['r2_train']),\n",
    "        'Pred_Train_Mean': np.mean(metrics['pred_train_mean'])\n",
    "\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250dc05",
   "metadata": {},
   "source": [
    "Model 5 performs the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3f983",
   "metadata": {},
   "source": [
    "### Logistic Regression with Cross-Validation for X1:X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a2f9b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-09 20:58:38.339735 Running regression for Logit_Model_X1...\n",
      "2026-02-09 20:58:44.406487 Running regression for Logit_Model_X2...\n",
      "2026-02-09 20:58:48.640184 Running regression for Logit_Model_X3...\n",
      "2026-02-09 20:59:46.903420 Running regression for Logit_Model_X4...\n",
      "2026-02-09 21:04:10.232606 Running regression for Logit_Model_X5...\n"
     ]
    }
   ],
   "source": [
    "#This takes a while, 4min 35sec for me, but it is necessary for getting the accurate scores\n",
    "train_idx = X_train.index\n",
    "\n",
    "logit_model_vars = {\n",
    "    \"Logit_Model_X1\": X1.loc[train_idx],\n",
    "    \"Logit_Model_X2\": X2.loc[train_idx],\n",
    "    \"Logit_Model_X3\": X3.loc[train_idx],\n",
    "    \"Logit_Model_X4\": X4.loc[train_idx],\n",
    "    \"Logit_Model_X5\": X5.loc[train_idx]\n",
    "}\n",
    "\n",
    "# Initialize storage dictionaries\n",
    "logit_models = {}\n",
    "CV_RMSE_folds = {}\n",
    "logit_accuracy = {}\n",
    "logit_auc = {}\n",
    "\n",
    "# Loop through the dictionary\n",
    "for name, X_data in logit_model_vars.items():\n",
    "    print(pd.Timestamp.now(), f'Running regression for {name}...')\n",
    "    \n",
    "    # Setup the Brier/RMSE Model\n",
    "    LRCV_brier = LogisticRegressionCV(\n",
    "        Cs=[1e20],  # No regularization (Standard Logit)\n",
    "        cv=k, \n",
    "        refit=True, \n",
    "        scoring='neg_brier_score', \n",
    "        solver=\"newton-cg\", \n",
    "        tol=1e-7, \n",
    "        random_state=20250224,\n",
    "        n_jobs=-1  \n",
    "    )\n",
    "    \n",
    "    # Fit & Store RMSE \n",
    "    model = LRCV_brier.fit(X_data, y_train)\n",
    "    logit_models[name] = model\n",
    "    \n",
    "    # Extract CV RMSE from the internal storage\n",
    "    raw_scores = model.scores_[1]\n",
    "    CV_RMSE_folds[name] = np.sqrt(-1 * raw_scores).flatten()\n",
    "    \n",
    "    # Calculate CV Accuracy \n",
    "    acc_scores = cross_val_score(model, X_data, y_train, cv=k, scoring='accuracy', n_jobs=-1)\n",
    "    logit_accuracy[name] = acc_scores.mean() \n",
    "    \n",
    "    # Calculate CV AUC\n",
    "    auc_scores = cross_val_score(model, X_data, y_train, cv=k, scoring='roc_auc', n_jobs=-1)\n",
    "    logit_auc[name] = auc_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0ef3c5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logit_Model_X1</td>\n",
       "      <td>0.4225</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logit_Model_X2</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logit_Model_X3</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.5095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logit_Model_X4</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logit_Model_X5</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.7649</td>\n",
       "      <td>0.5005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model    RMSE  Accuracy     AUC\n",
       "0  Logit_Model_X1  0.4225    0.7681  0.4895\n",
       "1  Logit_Model_X2  0.4227    0.7679  0.5017\n",
       "2  Logit_Model_X3  0.4228    0.7677  0.5095\n",
       "3  Logit_Model_X4  0.4239    0.7675  0.5030\n",
       "4  Logit_Model_X5  0.4264    0.7649  0.5005"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows = []\n",
    "\n",
    "for name in logit_models.keys():\n",
    "    avg_rmse = np.mean(CV_RMSE_folds[name])\n",
    "    # Get the score you stored (Note: for LogisticRegression, .score() is Accuracy)\n",
    "    \n",
    "    table_rows.append({\n",
    "        'Model': name,\n",
    "        'RMSE': avg_rmse,\n",
    "        'Accuracy': logit_accuracy[name],\n",
    "        'AUC': logit_auc[name]\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "logit_summary_table = pd.DataFrame(table_rows)\n",
    "logit_summary_table = logit_summary_table.round(4)\n",
    "logit_summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec4d44a",
   "metadata": {},
   "source": [
    "The best model is Model 4 and 5 are equaly good, 4 is simpler so we prefer that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa5187",
   "metadata": {},
   "source": [
    "### Lasso Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "82c3f885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LASSO (Optimizing for RMSE)...\n"
     ]
    }
   ],
   "source": [
    "X_train_data = logitvars.loc[train_idx]\n",
    "y_train_data = y_train\n",
    "\n",
    "# Define Hyperparameters (Lambdas -> Cs)\n",
    "lambdas = list(10**np.arange(-1, -4.01, -1/3))\n",
    "n_obs = len(X_train_data) * 4/5 \n",
    "Cs_values = [1/(l*n_obs) for l in lambdas]\n",
    "\n",
    "#Create & Fit the RMSE-Optimized Model (Brier Score)\n",
    "# We use a Pipeline to scale data INSIDE the CV loop (prevents leakage)\n",
    "lasso_rmse_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', LogisticRegressionCV(\n",
    "        Cs=Cs_values,\n",
    "        penalty='l1',\n",
    "        cv=k,                        \n",
    "        scoring='neg_brier_score',  \n",
    "        solver='liblinear',\n",
    "        random_state=42,\n",
    "        n_jobs=-1               \n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Running LASSO (Optimizing for RMSE)...\")\n",
    "lasso_rmse_pipe.fit(X_train_data, y_train_data)\n",
    "\n",
    "# --- EXTRACTING RESULTS ---\n",
    "\n",
    "model_internal = lasso_rmse_pipe.named_steps['lasso']\n",
    "\n",
    "# .scores_[1] gives shape (n_folds, n_Cs). Mean across folds.\n",
    "mean_brier_scores = model_internal.scores_[1].mean(axis=0)\n",
    "\n",
    "# Find the best score (Max because it's negative brier)\n",
    "best_brier_idx = np.argmax(mean_brier_scores)\n",
    "best_brier_score = mean_brier_scores[best_brier_idx]\n",
    "best_rmse = np.sqrt(-1 * best_brier_score)\n",
    "\n",
    "# Get the Best Hyperparameters (C and Lambda)\n",
    "best_C = model_internal.Cs_[best_brier_idx]\n",
    "best_lambda_val = 1 / (best_C * n_obs)\n",
    "\n",
    "\n",
    "# Calculate Accuracy an AUC\n",
    "winner_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso_fixed', LogisticRegression(\n",
    "        C=best_C,        # <--- The winner from Step 1\n",
    "        penalty='l1', \n",
    "        solver='liblinear', \n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Run 5-fold CV just for this one best configuration to get accuracy and AUC\n",
    "acc_scores = cross_val_score(winner_model, X_train_data, y_train_data, cv=k, scoring='accuracy')\n",
    "corresponding_accuracy = acc_scores.mean()\n",
    "\n",
    "auc_scores = cross_val_score(winner_model, X_train_data, y_train_data, cv=k, scoring='roc_auc')\n",
    "final_auc = auc_scores.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e215964e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimized_For</th>\n",
       "      <th>Best_Lambda</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LASSO Logit</td>\n",
       "      <td>RMSE (Brier)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4223</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.4941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Optimized_For  Best_Lambda    RMSE  Accuracy     AUC\n",
       "0  LASSO Logit  RMSE (Brier)         0.01  0.4223    0.7681  0.4941"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_summary_table = pd.DataFrame([{\n",
    "    'Model': 'LASSO Logit',\n",
    "    'Optimized_For': 'RMSE (Brier)',\n",
    "    'Best_Lambda': best_lambda_val,\n",
    "    'RMSE': best_rmse,\n",
    "    'Accuracy': corresponding_accuracy,\n",
    "    'AUC': final_auc\n",
    "}])\n",
    "\n",
    "lasso_summary_table.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cbe94290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logit_Model_X4</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LASSO Logit</td>\n",
       "      <td>0.4223</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.4941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model    RMSE  Accuracy     AUC\n",
       "3  Logit_Model_X4  0.4239    0.7675  0.5030\n",
       "0     LASSO Logit  0.4223    0.7681  0.4941"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_summary_table_small = lasso_summary_table[[\"Model\", \"RMSE\", \"Accuracy\", \"AUC\"]].round(4)\n",
    "logit_comparison_table = pd.concat([logit_summary_table[logit_summary_table[\"Model\"] == \"Logit_Model_X4\"], lasso_summary_table_small], axis=0)\n",
    "logit_comparison_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4229e83",
   "metadata": {},
   "source": [
    "Logit Model 4, 5 and LASSO Logit perform almost the same, lets choose model 4 for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0e8573ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Feature  Coefficient  Abs_Coef\n",
      "114                   C(ind2_cat)[33.0]:age2     0.019819  0.019819\n",
      "39                      share_eq_bs_flag_low     0.015026  0.015026\n",
      "145                 C(ind2_cat)[30.0]:female     0.010882  0.010882\n",
      "76   C(urban_m, Treatment(reference=1))[3.0]     0.009747  0.009747\n",
      "91         C(ind2_cat)[55.0]:C(urban_m)[2.0]     0.006580  0.006580\n",
      "25                personnel_exp_pl_flag_high     0.006424  0.006424\n",
      "77         C(ind2_cat)[26.0]:C(urban_m)[1.0]    -0.006328  0.006328\n",
      "2                            total_assets_bs     0.002483  0.002483\n",
      "32                material_exp_pl_flag_error     0.001287  0.001287\n",
      "33               personnel_exp_pl_flag_error     0.000031  0.000031\n"
     ]
    }
   ],
   "source": [
    "#Keep this in the code for demonstration:)\n",
    "\n",
    "# Access the fitted model step from your pipeline\n",
    "model_step = lasso_rmse_pipe.named_steps['lasso']\n",
    "\n",
    "# Extract coefficients\n",
    "# .coef_ is a list of lists. We grab the first one [0].\n",
    "coefs = model_internal.coef_[0]\n",
    "\n",
    "# We use abs() to find the strongest drivers regardless of + or - direction\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train_data.columns,\n",
    "    'Coefficient': coefs,\n",
    "    'Abs_Coef': np.abs(coefs)\n",
    "})\n",
    "\n",
    "# Sort by the biggest impact\n",
    "top_suspects = feature_importance.sort_values(by='Abs_Coef', ascending=False).head(10)\n",
    "\n",
    " # Data leak found: d1 values\n",
    "print(top_suspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565342a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5c09af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_idx = X_holdout.index\n",
    "X_train_rf = rfvars.loc[train_idx]\n",
    "X_holdout = rfvars.loc[holdout_idx]\n",
    "y_train_rf = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a425604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Random Forest Grid Search...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Detailed Results (All Combinations) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max_Features</th>\n",
       "      <th>Min_Samples_Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.4911</td>\n",
       "      <td>0.4264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.4871</td>\n",
       "      <td>0.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.4871</td>\n",
       "      <td>0.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.4271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7678</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.4272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.7678</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>0.4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.4274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>11</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.4274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Max_Features  Min_Samples_Split  Accuracy     AUC    RMSE\n",
       "1            5                 16    0.7681  0.4911  0.4264\n",
       "3            6                 16    0.7682  0.4871  0.4270\n",
       "7         sqrt                 16    0.7682  0.4871  0.4270\n",
       "0            5                 11    0.7681  0.4855  0.4271\n",
       "5            7                 16    0.7678  0.4890  0.4272\n",
       "4            7                 11    0.7678  0.4907  0.4273\n",
       "2            6                 11    0.7679  0.4868  0.4274\n",
       "6         sqrt                 11    0.7679  0.4868  0.4274"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Grid & Model\n",
    "grid = {\n",
    "    'max_features': [5, 6, 7, \"sqrt\"],\n",
    "    'criterion': ['gini'],\n",
    "    'min_samples_split': [11, 16],\n",
    "    'n_estimators': [500]\n",
    "}\n",
    "\n",
    "prob_forest = RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    n_estimators=100,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "# Run Grid Search\n",
    "prob_forest_grid = GridSearchCV(\n",
    "    prob_forest, \n",
    "    grid, \n",
    "    cv=5, \n",
    "    refit='neg_brier_score',  \n",
    "    scoring=['accuracy', 'roc_auc', 'neg_brier_score'], \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Running Random Forest Grid Search...\")\n",
    "prob_forest_grid.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# --- TABLE 1: DETAILED RESULTS (Every Combination) ---\n",
    "\n",
    "# Extract results into a DataFrame\n",
    "cv_results = pd.DataFrame(prob_forest_grid.cv_results_)\n",
    "\n",
    "# Keep only the columns we care about\n",
    "cols_to_keep = ['param_max_features', 'param_min_samples_split', \n",
    "                'mean_test_accuracy', 'mean_test_roc_auc', 'mean_test_neg_brier_score']\n",
    "summary_table = cv_results[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns for readability\n",
    "summary_table.columns = ['Max_Features', 'Min_Samples_Split', 'Accuracy', 'AUC', 'Neg_Brier']\n",
    "\n",
    "# Calculate RMSE from Neg_Brier\n",
    "summary_table['RMSE'] = np.sqrt(-1 * summary_table['Neg_Brier'])\n",
    "\n",
    "# Drop the confusing 'Neg_Brier' column now that we have RMSE\n",
    "summary_table = summary_table.drop(columns=['Neg_Brier'])\n",
    "\n",
    "# Sort by Lowest RMSE (Best Probabilities)\n",
    "summary_table = summary_table.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "print(\"\\n--- Detailed Results (All Combinations) ---\")\n",
    "summary_table.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c523cc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Random Forest Model Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimized_For</th>\n",
       "      <th>Max_Features</th>\n",
       "      <th>Min_Samples_Split</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>RMSE (Manual Sort)</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.4911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model       Optimized_For  Max_Features  Min_Samples_Split    RMSE  \\\n",
       "0  Random Forest  RMSE (Manual Sort)             5                 16  0.4264   \n",
       "\n",
       "   Accuracy     AUC  \n",
       "0    0.7681  0.4911  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- TABLE 2: BEST MODEL SUMMARY ---\n",
    "\n",
    "best_row = summary_table.iloc[0] # The row with lowest RMSE\n",
    "\n",
    "best_rf_summary = pd.DataFrame([{\n",
    "    'Model': 'Random Forest',\n",
    "    'Optimized_For': 'RMSE (Manual Sort)',\n",
    "    'Max_Features': best_row['Max_Features'],\n",
    "    'Min_Samples_Split': best_row['Min_Samples_Split'],\n",
    "    'RMSE': best_row['RMSE'],\n",
    "    'Accuracy': best_row['Accuracy'],\n",
    "    'AUC': best_row['AUC']\n",
    "}])\n",
    "\n",
    "print(\"\\n--- Best Random Forest Model Summary ---\")\n",
    "best_rf_summary.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f70df",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a63e905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradient Boosting Grid Search...\n",
      "\n",
      "--- Gradient Boosting Results (Top 5) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_Rate</th>\n",
       "      <th>N_Estimators</th>\n",
       "      <th>Max_Depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.7811</td>\n",
       "      <td>0.3753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.3754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8060</td>\n",
       "      <td>0.7811</td>\n",
       "      <td>0.3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.3758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.10</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>0.3758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning_Rate  N_Estimators  Max_Depth  Accuracy     AUC    RMSE\n",
       "1           0.05           200          3    0.8076  0.7811  0.3753\n",
       "6           0.10           100          3    0.8088  0.7797  0.3754\n",
       "3           0.05           100          5    0.8060  0.7811  0.3757\n",
       "4           0.05           200          5    0.8079  0.7805  0.3758\n",
       "7           0.10           200          3    0.8079  0.7799  0.3758"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup Data\n",
    "X_train_gb = rfvars.loc[train_idx] # Use the same clean vars as Random Forest\n",
    "y_train_gb = y_train\n",
    "\n",
    "# Define the Hyperparameter Grid\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 500],         \n",
    "    'learning_rate': [0.05, 0.1, 0.2],  \n",
    "    'max_depth': [3, 5],               \n",
    "}           \n",
    "\n",
    "# Setup Model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Run Grid Search with Multiple Metrics\n",
    "gb_grid = GridSearchCV(\n",
    "    gb_model, \n",
    "    gb_params, \n",
    "    cv=5, \n",
    "    refit='neg_brier_score',  # Optimize for best PROBABILITY (RMSE)\n",
    "    scoring=['accuracy', 'roc_auc', 'neg_brier_score'], \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Running Gradient Boosting Grid Search...\")\n",
    "gb_grid.fit(X_train_gb, y_train_gb)\n",
    "\n",
    "# --- TABLE 1: DETAILED RESULTS ---\n",
    "\n",
    "cv_results_gb = pd.DataFrame(gb_grid.cv_results_)\n",
    "\n",
    "# Select and rename columns\n",
    "cols_gb = ['param_learning_rate', 'param_n_estimators', 'param_max_depth', \n",
    "           'mean_test_accuracy', 'mean_test_roc_auc', 'mean_test_neg_brier_score']\n",
    "\n",
    "gb_summary = cv_results_gb[cols_gb].copy()\n",
    "gb_summary.columns = ['Learning_Rate', 'N_Estimators', 'Max_Depth', 'Accuracy', 'AUC', 'Neg_Brier']\n",
    "\n",
    "# Calculate RMSE\n",
    "gb_summary['RMSE'] = np.sqrt(-1 * gb_summary['Neg_Brier'])\n",
    "gb_summary = gb_summary.drop(columns=['Neg_Brier'])\n",
    "\n",
    "# Sort by Best RMSE\n",
    "gb_summary = gb_summary.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "print(\"\\n--- Gradient Boosting Results (Top 5) ---\")\n",
    "gb_summary.head(5).round(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d84fa480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Gradient Boosting Model ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimized_For</th>\n",
       "      <th>Learning_Rate</th>\n",
       "      <th>N_Estimators</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>RMSE (Brier)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.3753</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.7811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Optimized_For  Learning_Rate  N_Estimators    RMSE  \\\n",
       "0  Gradient Boosting  RMSE (Brier)           0.05         200.0  0.3753   \n",
       "\n",
       "   Accuracy     AUC  \n",
       "0    0.8076  0.7811  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- TABLE 2: BEST MODEL SUMMARY ---\n",
    "\n",
    "best_row_gb = gb_summary.iloc[0]\n",
    "\n",
    "best_gb_summary = pd.DataFrame([{\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'Optimized_For': 'RMSE (Brier)',\n",
    "    'Learning_Rate': best_row_gb['Learning_Rate'],\n",
    "    'N_Estimators': best_row_gb['N_Estimators'],\n",
    "    'RMSE': best_row_gb['RMSE'],\n",
    "    'Accuracy': best_row_gb['Accuracy'],\n",
    "    'AUC': best_row_gb['AUC']\n",
    "}])\n",
    "\n",
    "print(\"\\n--- Best Gradient Boosting Model ---\")\n",
    "best_gb_summary.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa730ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full Model Comparison Table ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logit_Model_X4</td>\n",
       "      <td>0.3837</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.7585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LASSO Logit</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.3753</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.7811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.3770</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>0.7747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    RMSE  Accuracy     AUC\n",
       "3     Logit_Model_X4  0.3837    0.8017  0.7585\n",
       "0        LASSO Logit  0.3817    0.8029  0.7613\n",
       "0  Gradient Boosting  0.3753    0.8076  0.7811\n",
       "0      Random Forest  0.3770    0.8062  0.7747"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb_summary_small = best_gb_summary[[\"Model\", \"RMSE\", \"Accuracy\", \"AUC\"]].round(4)\n",
    "best_rf_summary_small = best_rf_summary[[\"Model\", \"RMSE\", \"Accuracy\", \"AUC\"]].round(4)\n",
    "\n",
    "print(\"\\n--- Full Model Comparison Table ---\")\n",
    "full_comparison_table = pd.concat([logit_comparison_table, best_gb_summary_small, best_rf_summary_small], axis=0)\n",
    "full_comparison_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da8778",
   "metadata": {},
   "source": [
    "The best probability predictor of fast growth is the gradient boost model, according to all observed metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48940ef",
   "metadata": {},
   "source": [
    "# PART II: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7ef7c",
   "metadata": {},
   "source": [
    "Think about the business problem, and define your loss function (like FP=X dollars, FN=Y dollars).\n",
    "\n",
    "Idea 1: We have some spare money and want to do some investments. Overall, riskier firms, thus firms with a higher probability to default also pay higher returns. On the other hand, we lose money when a risky firm defaults. The money lost from an unexpected default is about the same, as money lost from a risky firm that ends up well performing that we decided not to invest in.\n",
    "Therefore, a suggested loss function would be:\n",
    "FP = 0.5 FN = 0.5\n",
    "\n",
    "\n",
    "Idea 2: I think it is a wrong logic to assign the same loss to both cases. Loosing all the money with a default is a much bigger blow than missing an oportunity. If we miss something (FN) we can still invest our money, if we invest in something that defaults (FP), we loose all our money, and we can't invest in something else.\n",
    "My suggestion is: FP = 0.75, FN = 0.25\n",
    "\n",
    "Also we should make up some \"bussnies scenario\" so we can write the summary that way. So instead of having \"spare money\" we should be an analyst at an investment firm, who has been tasked to help build a model for making a high risk - high reward portfolio for risk taking investors, but our prime mandate is not to loose their money.\n",
    "\n",
    "\n",
    "Fair points :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#use the best models from PART I for classification with the loss function\n",
    "#Test all tresholds (how much certenty do we need to invest in a company)\n",
    "#Pick model and treshold combination that results in lowest loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b36cc",
   "metadata": {},
   "source": [
    "#### Redefining some models because they weren't saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a9fb63c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LASSO...\n",
      "Model is fitted.\n"
     ]
    }
   ],
   "source": [
    "# LASSO LOGIT\n",
    "\n",
    "# 1. Define the pipeline\n",
    "lasso_logit = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', LogisticRegressionCV(\n",
    "        Cs=Cs_values,\n",
    "        penalty='l1',\n",
    "        cv=5,                        \n",
    "        scoring='neg_brier_score',  \n",
    "        solver='liblinear',\n",
    "        random_state=42,\n",
    "        n_jobs=-1               \n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2. Fit and RE-ASSIGN (Crucial step)\n",
    "print(\"Fitting LASSO...\")\n",
    "lasso_logit = lasso_logit.fit(logitvars.loc[y_train.index], y_train)\n",
    "\n",
    "# 3. Final Verification\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "check_is_fitted(lasso_logit.named_steps['lasso'])\n",
    "print(\"Model is fitted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "76749029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Random Forest Grid Search...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(oob_score=True, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;max_features&#x27;: [5],\n",
       "                         &#x27;min_samples_split&#x27;: [16], &#x27;n_estimators&#x27;: [500]},\n",
       "             refit=&#x27;neg_brier_score&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;roc_auc&#x27;, &#x27;neg_brier_score&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">RandomForestC...ndom_state=42)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;max_features&#x27;: [5], &#x27;min_samples_split&#x27;: [16], &#x27;n_estimators&#x27;: [500]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;accuracy&#x27;, &#x27;roc_auc&#x27;, ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;neg_brier_score&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>RandomForestClassifier(max_features=5, min_samples_split=16, n_estimators=500,\n",
       "                       oob_score=True, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">16</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(oob_score=True, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini'], 'max_features': [5],\n",
       "                         'min_samples_split': [16], 'n_estimators': [500]},\n",
       "             refit='neg_brier_score',\n",
       "             scoring=['accuracy', 'roc_auc', 'neg_brier_score'])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest ##\n",
    "\n",
    "# Define Grid & Model\n",
    "grid = {\n",
    "    'max_features': [5],\n",
    "    'criterion': ['gini'],\n",
    "    'min_samples_split': [16],\n",
    "    'n_estimators': [500]\n",
    "}\n",
    "\n",
    "prob_forest = RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    n_estimators=100,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "# Run Grid Search\n",
    "prob_forest_grid = GridSearchCV(\n",
    "    prob_forest, \n",
    "    grid, \n",
    "    cv=5, \n",
    "    refit='neg_brier_score',  \n",
    "    scoring=['accuracy', 'roc_auc', 'neg_brier_score'], \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Running Random Forest Grid Search...\")\n",
    "prob_forest_grid.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ce3f5eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradient Boosting Grid Search...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gradient Boosting Results (Top 5) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_Rate</th>\n",
       "      <th>N_Estimators</th>\n",
       "      <th>Max_Depth</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7636</td>\n",
       "      <td>0.5111</td>\n",
       "      <td>0.4275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning_Rate  N_Estimators  Max_Depth  Accuracy     AUC    RMSE\n",
       "0           0.05           200          5    0.7636  0.5111  0.4275"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GBM ##\n",
    "\n",
    "\n",
    "# Setup Data\n",
    "X_train_gb = rfvars.iloc[train_idx] # Use the same clean vars as Random Forest\n",
    "y_train_gb = y_train.iloc[train_idx]\n",
    "\n",
    "# Define the Hyperparameter Grid\n",
    "gb_params = {\n",
    "    'n_estimators': [200],         \n",
    "    'learning_rate': [0.05],  \n",
    "    'max_depth': [5]}           \n",
    "\n",
    "# Setup Model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Run Grid Search with Multiple Metrics\n",
    "gb_grid = GridSearchCV(\n",
    "    gb_model, \n",
    "    gb_params, \n",
    "    cv=5, \n",
    "    refit='neg_brier_score',  # Optimize for best PROBABILITY (RMSE)\n",
    "    scoring=['accuracy', 'roc_auc', 'neg_brier_score'], \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Running Gradient Boosting Grid Search...\")\n",
    "gb_grid.fit(X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "221db72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map = {\n",
    "    \"Logit_Model_X4\": {\"model\": logit_models[\"Logit_Model_X4\"], \"data\": X4.loc[y_train.index]},\n",
    "   \"Lasso_Logit\": {\"model\": lasso_logit, \"data\": logitvars.loc[y_train.index]},\n",
    "   \"GBM\": {\"model\": gb_grid, \"data\": rfvars.iloc[train_idx]},\n",
    "   \"RF\": {\"model\": prob_forest_grid, \"data\": X_train_rf}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "41c1d483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit_Model_X4 -> Avg Threshold: inf, Avg Loss: 0.0580\n",
      "Lasso_Logit -> Avg Threshold: 0.7320, Avg Loss: 0.0542\n",
      "GBM -> Avg Threshold: inf, Avg Loss: 0.0573\n",
      "RF -> Avg Threshold: 0.3449, Avg Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "\n",
    "\n",
    "# 1. Setup Costs and Prevalence\n",
    "FP, FN = 0.75, 0.25\n",
    "cost_ratio = FN / FP\n",
    "prevalence = y_train.mean()\n",
    "\n",
    "# Define the models and their corresponding X dataframes\n",
    "# Mapping them clearly prevents indexing errors\n",
    "#model_map = {\n",
    "#    \"Logit_Model_X4\": {\"model\": logit_models[\"Logit_Model_X4\"], \"data\": X4.loc[y_train.index]},\n",
    "#    \"Lasso_Logit\": {\"model\": winner_model, \"data\": logitvars.loc[y_train.index]}\n",
    "#}\n",
    "\n",
    "# Results containers\n",
    "cv_results = {}\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=20250224)\n",
    "\n",
    "for name, setup in model_map.items():\n",
    "    model = setup[\"model\"]\n",
    "    X = setup[\"data\"]\n",
    "    \n",
    "    fold_thresholds = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        # Split data for the fold\n",
    "        X_fold_test = X.iloc[test_idx]\n",
    "        y_fold_test = y_train.iloc[test_idx]\n",
    "        \n",
    "        # Predict probabilities\n",
    "        # Pipeline (Lasso) handles scaling automatically; Logit X4 uses raw X\n",
    "        probs = model.predict_proba(X_fold_test)[:, 1]\n",
    "        \n",
    "        # Calculate ROC\n",
    "        fpr, tpr, thresholds = roc_curve(y_fold_test, probs)\n",
    "        \n",
    "        # 2. Simplified Optimal Threshold Calculation\n",
    "        # We want to minimize: Loss = FPR * (1-prev) * FP + FNR * prev * FN\n",
    "        # Equivalent to maximizing: TPR - (FPR * (1-prev)/prev * (FP/FN))\n",
    "        weighted_stat = tpr - (fpr * ((1 - prevalence) / (prevalence * cost_ratio)))\n",
    "        ix = np.argmax(weighted_stat)\n",
    "        best_t = thresholds[ix]\n",
    "        \n",
    "        # Calculate Loss for this fold\n",
    "        preds = (probs >= best_t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_fold_test, preds).ravel()\n",
    "        loss = (fp * FP + fn * FN) / len(y_fold_test)\n",
    "        \n",
    "        fold_thresholds.append(best_t)\n",
    "        fold_losses.append(loss)\n",
    "\n",
    "    # Store results\n",
    "    cv_results[name] = {\n",
    "        \"avg_threshold\": np.mean(fold_thresholds),\n",
    "        \"avg_loss\": np.mean(fold_losses),\n",
    "        \"last_fold_all_coords\": pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds})\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} -> Avg Threshold: {cv_results[name]['avg_threshold']:.4f}, Avg Loss: {cv_results[name]['avg_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0dd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2431,  283])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb482ad",
   "metadata": {},
   "source": [
    "## MODELS WE CAN'T USE  :/\n",
    "\n",
    "My dumb ass forgot that we have binary outcome variables and calculated all the regular models.\n",
    "\n",
    "For now, I'm keeping them in the script in case that some  of the syntax might come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592f622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd06e45",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40da8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define model\n",
    "model = Lasso()\n",
    "\n",
    "grid = dict()\n",
    "grid[\"alpha\"] = np.arange(0.05, 1, 0.05)\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring=\"neg_root_mean_squared_error\", cv = k, verbose= 3) # control your output with the 'verbose' option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c9d79de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.398 total time=   0.3s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.393 total time=   0.3s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.416 total time=   0.3s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.409 total time=   0.2s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.401 total time=   0.2s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.399 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.398 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.420 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.413 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.405 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.402 total time=   0.1s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.401 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.422 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.416 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.402 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.401 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.423 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.416 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.401 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.402 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.402 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.402 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.403 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.418 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.403 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.424 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.418 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.403 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.425 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.404 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.426 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.426 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.426 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.409 total time=   0.0s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.408 total time=   0.3s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.402 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.401 total time=   0.2s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.413 total time=   0.2s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.394 total time=   0.2s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.412 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.406 total time=   0.2s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.405 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.415 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.398 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.414 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.409 total time=   0.1s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.407 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.401 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.409 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.408 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.401 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.409 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.408 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.402 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.410 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.419 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.409 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.402 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.415 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.410 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.417 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.417 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.404 total time=   0.0s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.398 total time=   0.4s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.408 total time=   0.2s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.402 total time=   0.3s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.403 total time=   0.2s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.402 total time=   0.2s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.402 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.410 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.407 total time=   0.2s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.406 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.405 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.408 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.412 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.409 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.408 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.410 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.409 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.408 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.413 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.410 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.409 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.408 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.409 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.409 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.408 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.413 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.409 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.410 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.411 total time=   0.0s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.396 total time=   0.2s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.406 total time=   0.2s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.401 total time=   0.2s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.414 total time=   0.6s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.394 total time=   0.3s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.399 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.411 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.407 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.416 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.399 total time=   0.2s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.402 total time=   0.1s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.413 total time=   0.1s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.410 total time=   0.2s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.419 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.401 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.413 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.410 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.420 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.402 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.414 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.420 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.414 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.421 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.403 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.421 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.403 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.421 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.403 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.414 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.421 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.403 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.415 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.415 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.422 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.422 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.416 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.413 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.422 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.405 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.416 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.413 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.422 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.406 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.416 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.423 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.416 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.423 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.1s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.404 total time=   0.4s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.411 total time=   0.3s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.406 total time=   0.3s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.402 total time=   0.3s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.405 total time=   0.2s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.409 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.408 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.406 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.410 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.411 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.417 total time=   0.1s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.409 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.412 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.411 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.418 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.409 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.412 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.411 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.419 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.410 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.413 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.412 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.419 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.410 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.413 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.412 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.419 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.410 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.413 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.412 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.419 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.410 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.413 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.412 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.419 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.410 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.414 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.413 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.419 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.414 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.413 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.420 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.414 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.411 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.411 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.415 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.415 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.414 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.421 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.415 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.421 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.416 total time=   0.0s\n",
      "Train RMSE: 0.4027 vs Test RMSE: 0.4036\n",
      "Train R2:   0.0896 vs Test R2:   0.0849\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for both sets\n",
    "rmse_lasso_test, r2_lasso_test = [], []\n",
    "rmse_lasso_train, r2_lasso_train = [], []\n",
    "pred_lasso_test, pred_lasso_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = logitvars.iloc[train_index], logitvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### LASSO MODEL ###\n",
    "    lasso_mod = search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = lasso_mod.predict(X_test)\n",
    "    y_pred_train = lasso_mod.predict(X_train)\n",
    "    \n",
    "    pred_lasso_test.append(y_pred_test.mean())\n",
    "    pred_lasso_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_lasso_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_lasso_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_lasso_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_lasso_train.append(r2_score(y_train, y_pred_train))\n",
    "\n",
    "# Quick summary of the averages\n",
    "print(f\"Train RMSE: {np.mean(rmse_lasso_train):.4f} vs Test RMSE: {np.mean(rmse_lasso_test):.4f}\")\n",
    "print(f\"Train R2:   {np.mean(r2_lasso_train):.4f} vs Test R2:   {np.mean(r2_lasso_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ddbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "predicted train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2 train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rmse train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2 test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rmse test",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "63dba2aa-4de8-488e-b43f-ea53d5785b79",
       "rows": [
        [
         "0",
         "0.23208033904551317",
         "0.09018554027943337",
         "0.4026739046499711",
         "0.23407390310732187",
         "0.08238615374752101",
         "0.23407390310732187"
        ],
        [
         "1",
         "0.232540998710153",
         "0.09446467958524973",
         "0.40200370533431984",
         "0.23447246236188238",
         "0.0835443666926261",
         "0.23447246236188238"
        ],
        [
         "2",
         "0.22876358946010691",
         "0.09267903949944956",
         "0.40009920223093925",
         "0.23092428902430065",
         "0.0964049987281338",
         "0.23092428902430065"
        ],
        [
         "3",
         "0.23076923076923078",
         "0.09304949188652156",
         "0.40124447861344736",
         "0.23026279239086223",
         "0.08391880490751924",
         "0.23026279239086223"
        ],
        [
         "4",
         "0.23519115614924",
         "0.0987022687909832",
         "0.40264386205925434",
         "0.23039357024303742",
         "0.09809752525404059",
         "0.23039357024303742"
        ],
        [
         "Average",
         "0.23186906282684877",
         "0.09381620400832749",
         "0.40173303057758647",
         "0.2320254034254809",
         "0.08887036986596815",
         "0.2320254034254809"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted train</th>\n",
       "      <th>r2 train</th>\n",
       "      <th>rmse train</th>\n",
       "      <th>predicted test</th>\n",
       "      <th>r2 test</th>\n",
       "      <th>rmse test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232080</td>\n",
       "      <td>0.090186</td>\n",
       "      <td>0.402674</td>\n",
       "      <td>0.234074</td>\n",
       "      <td>0.082386</td>\n",
       "      <td>0.234074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232541</td>\n",
       "      <td>0.094465</td>\n",
       "      <td>0.402004</td>\n",
       "      <td>0.234472</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.234472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.228764</td>\n",
       "      <td>0.092679</td>\n",
       "      <td>0.400099</td>\n",
       "      <td>0.230924</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.230924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.093049</td>\n",
       "      <td>0.401244</td>\n",
       "      <td>0.230263</td>\n",
       "      <td>0.083919</td>\n",
       "      <td>0.230263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235191</td>\n",
       "      <td>0.098702</td>\n",
       "      <td>0.402644</td>\n",
       "      <td>0.230394</td>\n",
       "      <td>0.098098</td>\n",
       "      <td>0.230394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.231869</td>\n",
       "      <td>0.093816</td>\n",
       "      <td>0.401733</td>\n",
       "      <td>0.232025</td>\n",
       "      <td>0.088870</td>\n",
       "      <td>0.232025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         predicted train  r2 train  rmse train  predicted test   r2 test  \\\n",
       "0               0.232080  0.090186    0.402674        0.234074  0.082386   \n",
       "1               0.232541  0.094465    0.402004        0.234472  0.083544   \n",
       "2               0.228764  0.092679    0.400099        0.230924  0.096405   \n",
       "3               0.230769  0.093049    0.401244        0.230263  0.083919   \n",
       "4               0.235191  0.098702    0.402644        0.230394  0.098098   \n",
       "Average         0.231869  0.093816    0.401733        0.232025  0.088870   \n",
       "\n",
       "         rmse test  \n",
       "0         0.234074  \n",
       "1         0.234472  \n",
       "2         0.230924  \n",
       "3         0.230263  \n",
       "4         0.230394  \n",
       "Average   0.232025  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lasso_mod = {\n",
    "        \"predicted train\": pred_lasso_train,\n",
    "        \"r2 train\": r2_lasso_train,\n",
    "        \"rmse train\": rmse_lasso_train,\n",
    "        \"predicted test\": pred_lasso_test,\n",
    "        \"r2 test\": r2_lasso_test,\n",
    "        \"rmse test\": pred_lasso_test\n",
    "    }\n",
    "results_lasso_mod = pd.concat([pd.DataFrame(results_lasso_mod), pd.DataFrame(pd.DataFrame(results_lasso_mod).mean(), columns=[\"Average\"]).T])\n",
    "results_lasso_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10def78a",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7124297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(random_state = 20250224)\n",
    "tune_grid = {\"max_features\": [6, 8, 10, 12], \"min_samples_leaf\": [5, 10, 15]}\n",
    "\n",
    "rf_random = GridSearchCV(\n",
    "    estimator = rfr,\n",
    "    param_grid = tune_grid,\n",
    "    cv = 5,\n",
    "    scoring = \"neg_root_mean_squared_error\",\n",
    "    verbose = 3,\n",
    ")\n",
    "# Built into grid search, it will run on the test set, not on the train set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END max_features=6, min_samples_leaf=5;, score=-0.151 total time=   1.0s\n",
      "[CV 2/5] END max_features=6, min_samples_leaf=5;, score=-0.148 total time=   0.9s\n",
      "[CV 3/5] END max_features=6, min_samples_leaf=5;, score=-0.149 total time=   1.0s\n",
      "[CV 4/5] END max_features=6, min_samples_leaf=5;, score=-0.146 total time=   1.0s\n",
      "[CV 5/5] END max_features=6, min_samples_leaf=5;, score=-0.143 total time=   1.0s\n",
      "[CV 1/5] END max_features=6, min_samples_leaf=10;, score=-0.155 total time=   0.9s\n",
      "[CV 2/5] END max_features=6, min_samples_leaf=10;, score=-0.154 total time=   0.9s\n",
      "[CV 3/5] END max_features=6, min_samples_leaf=10;, score=-0.155 total time=   0.9s\n",
      "[CV 4/5] END max_features=6, min_samples_leaf=10;, score=-0.151 total time=   0.9s\n",
      "[CV 5/5] END max_features=6, min_samples_leaf=10;, score=-0.157 total time=   0.9s\n",
      "[CV 1/5] END max_features=6, min_samples_leaf=15;, score=-0.162 total time=   0.9s\n",
      "[CV 2/5] END max_features=6, min_samples_leaf=15;, score=-0.154 total time=   0.9s\n",
      "[CV 3/5] END max_features=6, min_samples_leaf=15;, score=-0.157 total time=   0.9s\n",
      "[CV 4/5] END max_features=6, min_samples_leaf=15;, score=-0.159 total time=   0.9s\n",
      "[CV 5/5] END max_features=6, min_samples_leaf=15;, score=-0.152 total time=   0.9s\n",
      "[CV 1/5] END max_features=8, min_samples_leaf=5;, score=-0.137 total time=   1.0s\n",
      "[CV 2/5] END max_features=8, min_samples_leaf=5;, score=-0.136 total time=   1.0s\n",
      "[CV 3/5] END max_features=8, min_samples_leaf=5;, score=-0.133 total time=   1.1s\n",
      "[CV 4/5] END max_features=8, min_samples_leaf=5;, score=-0.132 total time=   1.0s\n",
      "[CV 5/5] END max_features=8, min_samples_leaf=5;, score=-0.126 total time=   1.0s\n",
      "[CV 1/5] END max_features=8, min_samples_leaf=10;, score=-0.143 total time=   1.0s\n",
      "[CV 2/5] END max_features=8, min_samples_leaf=10;, score=-0.136 total time=   1.0s\n",
      "[CV 3/5] END max_features=8, min_samples_leaf=10;, score=-0.135 total time=   1.0s\n",
      "[CV 4/5] END max_features=8, min_samples_leaf=10;, score=-0.132 total time=   1.0s\n",
      "[CV 5/5] END max_features=8, min_samples_leaf=10;, score=-0.129 total time=   1.0s\n",
      "[CV 1/5] END max_features=8, min_samples_leaf=15;, score=-0.144 total time=   1.0s\n",
      "[CV 2/5] END max_features=8, min_samples_leaf=15;, score=-0.138 total time=   1.0s\n",
      "[CV 3/5] END max_features=8, min_samples_leaf=15;, score=-0.140 total time=   1.0s\n",
      "[CV 4/5] END max_features=8, min_samples_leaf=15;, score=-0.139 total time=   1.0s\n",
      "[CV 5/5] END max_features=8, min_samples_leaf=15;, score=-0.133 total time=   1.0s\n",
      "[CV 1/5] END max_features=10, min_samples_leaf=5;, score=-0.135 total time=   1.1s\n",
      "[CV 2/5] END max_features=10, min_samples_leaf=5;, score=-0.128 total time=   1.2s\n",
      "[CV 3/5] END max_features=10, min_samples_leaf=5;, score=-0.130 total time=   1.2s\n",
      "[CV 4/5] END max_features=10, min_samples_leaf=5;, score=-0.123 total time=   1.1s\n",
      "[CV 5/5] END max_features=10, min_samples_leaf=5;, score=-0.122 total time=   1.1s\n",
      "[CV 1/5] END max_features=10, min_samples_leaf=10;, score=-0.135 total time=   1.1s\n",
      "[CV 2/5] END max_features=10, min_samples_leaf=10;, score=-0.131 total time=   1.1s\n",
      "[CV 3/5] END max_features=10, min_samples_leaf=10;, score=-0.131 total time=   1.1s\n",
      "[CV 4/5] END max_features=10, min_samples_leaf=10;, score=-0.126 total time=   1.1s\n",
      "[CV 5/5] END max_features=10, min_samples_leaf=10;, score=-0.123 total time=   1.1s\n",
      "[CV 1/5] END max_features=10, min_samples_leaf=15;, score=-0.138 total time=   1.1s\n",
      "[CV 2/5] END max_features=10, min_samples_leaf=15;, score=-0.134 total time=   1.2s\n",
      "[CV 3/5] END max_features=10, min_samples_leaf=15;, score=-0.135 total time=   1.1s\n",
      "[CV 4/5] END max_features=10, min_samples_leaf=15;, score=-0.128 total time=   1.1s\n",
      "[CV 5/5] END max_features=10, min_samples_leaf=15;, score=-0.127 total time=   1.1s\n",
      "[CV 1/5] END max_features=12, min_samples_leaf=5;, score=-0.134 total time=   1.2s\n",
      "[CV 2/5] END max_features=12, min_samples_leaf=5;, score=-0.125 total time=   1.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m### Random Forest Model ###\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m rf_mod \u001b[38;5;241m=\u001b[39m \u001b[43mrf_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m rf_mod\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     18\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m rf_mod\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    994\u001b[0m         )\n\u001b[1;32m    995\u001b[0m     )\n\u001b[0;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:859\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    857\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    863\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:486\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    475\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    478\u001b[0m ]\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    197\u001b[0m         X,\n\u001b[1;32m    198\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Watch out, this takes 10 minutes to run!\n",
    " \n",
    "rmse_rf_test, r2_rf_test = [], []\n",
    "rmse_rf_train, r2_rf_train = [], []\n",
    "pred_rf_test, pred_rf_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = rfvars.iloc[train_index], rfvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### Random Forest Model ###\n",
    "    rf_mod = rf_random.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = rf_mod.predict(X_test)\n",
    "    y_pred_train = rf_mod.predict(X_train)\n",
    "    \n",
    "    pred_rf_test.append(y_pred_test.mean())\n",
    "    pred_rf_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_rf_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_rf_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_rf_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_rf_train.append(r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ee8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_mod = {\n",
    "        \"predicted train\": pred_rf_train,\n",
    "        \"r2 train\": r2_rf_train,\n",
    "        \"rmse train\": rmse_rf_train,\n",
    "        \"predicted test\": pred_rf_test,\n",
    "        \"r2 test\": r2_rf_test,\n",
    "        \"rmse test\": pred_rf_test\n",
    "    }\n",
    "results_rf_mod = pd.concat([pd.DataFrame(results_rf_mod), pd.DataFrame(pd.DataFrame(results_rf_mod).mean(), columns=[\"Average\"]).T])\n",
    "results_rf_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6913ad",
   "metadata": {},
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeRegressor(random_state=1234, criterion=\"squared_error\",max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cart_test, r2_cart_test = [], []\n",
    "rmse_cart_train, r2_cart_train = [], []\n",
    "pred_cart_test, pred_cart_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = rfvars.iloc[train_index], rfvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### Random Forest Model ###\n",
    "    cart_mod = cart.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = rf_mod.predict(X_test)\n",
    "    y_pred_train = rf_mod.predict(X_train)\n",
    "    \n",
    "    pred_cart_test.append(y_pred_test.mean())\n",
    "    pred_cart_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_cart_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_cart_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_cart_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_cart_train.append(r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d378213",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cart_mod = {\n",
    "        \"predicted train\": pred_cart_train,\n",
    "        \"r2 train\": r2_cart_train,\n",
    "        \"rmse train\": rmse_cart_train,\n",
    "        \"predicted test\": pred_cart_test,\n",
    "        \"r2 test\": r2_cart_test,\n",
    "        \"rmse test\": pred_cart_test\n",
    "    }\n",
    "results_cart_mod = pd.concat([pd.DataFrame(results_cart_mod), pd.DataFrame(pd.DataFrame(results_cart_mod).mean(), columns=[\"Average\"]).T])\n",
    "results_cart_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a1942",
   "metadata": {},
   "source": [
    "### BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor(learning_rate=0.1, min_samples_split=20, max_features = 10\n",
    "                                #, n_estimators = 50\n",
    "                               )\n",
    "\n",
    "tune_grid = {\"n_estimators\": [200, 300], \"max_depth\": [5, 10]}\n",
    "\n",
    "gbm_model_cv = GridSearchCV(\n",
    "    gbm,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Flatten categorical_columns and ensure no nested lists\n",
    "# We use a list comprehension to make sure we only grab strings\n",
    "raw_cat_list = engvar3 + [\"balsheet_notfullyear\", \"foreign_management\"]\n",
    "categorical_columns = []\n",
    "for item in raw_cat_list:\n",
    "    if isinstance(item, list):\n",
    "        categorical_columns.extend(item)\n",
    "    else:\n",
    "        categorical_columns.append(item)\n",
    "\n",
    "# 2. Flatten all_vars the same way\n",
    "final_all_vars = []\n",
    "for item in all_vars:\n",
    "    if isinstance(item, list):\n",
    "        final_all_vars.extend(item)\n",
    "    else:\n",
    "        final_all_vars.append(item)\n",
    "\n",
    "# 3. Filter numerical columns based on the flattened lists\n",
    "numerical_columns = [col for col in final_all_vars if col not in categorical_columns]\n",
    "\n",
    "# 4. Redefine Preprocessing\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Now try the fit again\n",
    "gbm_pipe = Pipeline([(\"preprocess\", preprocessing), (\"regressor\", gbm_model_cv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6721a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch out this takes 10 min to run!\n",
    "#\n",
    "r2_gbm_test, r2_gbm_train = [], []\n",
    "rmse_gbm_test, rmse_gbm_train = [], []\n",
    "pred_gbm_test, pred_gbm_train = [], []\n",
    "\n",
    "for train_index, test_index in k.split(firms_df[final_all_vars]):\n",
    "    \n",
    "    X_train, X_test = firms_df[final_all_vars].iloc[train_index], firms_df[final_all_vars].iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # 1. Fit the model\n",
    "    gbm_mod = gbm_pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. Predict for TRAIN and calculate metrics\n",
    "    y_pred_train = gbm_mod.predict(X_train)  # <--- Define this!\n",
    "    pred_gbm_train.append(y_pred_train.mean())\n",
    "    rmse_gbm_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_gbm_train.append(r2_score(y_train, y_pred_train))\n",
    "\n",
    "    # 3. Predict for TEST and calculate metrics\n",
    "    y_pred_test = gbm_mod.predict(X_test)    # <--- Define this!\n",
    "    pred_gbm_test.append(y_pred_test.mean())\n",
    "    rmse_gbm_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_gbm_test.append(r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb54043",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbm_mod = {\n",
    "        \"predicted train\": pred_gbm_train,\n",
    "        \"r2 train\": r2_gbm_train,\n",
    "        \"rmse train\": rmse_gbm_train,\n",
    "        \"predicted test\": pred_gbm_test,\n",
    "        \"r2 test\": r2_gbm_test,\n",
    "        \"rmse test\": pred_gbm_test\n",
    "    }\n",
    "results_gbm_mod = pd.concat([pd.DataFrame(results_gbm_mod), pd.DataFrame(pd.DataFrame(results_gbm_mod).mean(), columns=[\"Average\"]).T])\n",
    "#pd.DataFrame(results_gbm_mod)\n",
    "results_gbm_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb15b4",
   "metadata": {},
   "source": [
    "### GLM model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch out, this takes 10 minutes to run!\n",
    " \n",
    "rmse_glm_test, r2_glm_test = [], []\n",
    "rmse_glm_train, r2_glm_train = [], []\n",
    "pred_glm_test, pred_glm_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = rfvars.iloc[train_index], rfvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### GLM ###\n",
    "    glm_modelx1 = LogisticRegression(\n",
    "    solver = \"newton-cg\", \n",
    "    max_iter = 1000, \n",
    "    penalty = None, \n",
    "    random_state = 1234).fit(X_train, y_train)\n",
    "    #regression_results(y, glm_modelx1.predict(X1))\n",
    "\n",
    "    y_pred_test = glm_modelx1.predict(X_test)\n",
    "    y_pred_train = glm_modelx1.predict(X_train)\n",
    "    \n",
    "    pred_glm_test.append(y_pred_test.mean())\n",
    "    pred_glm_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_glm_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_glm_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_glm_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_glm_train.append(r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glm_modelx1 = {\n",
    "        \"predicted train\": pred_glm_train,\n",
    "        \"r2 train\": r2_glm_train,\n",
    "        \"rmse train\": rmse_glm_train,\n",
    "        \"predicted test\": pred_glm_test,\n",
    "        \"r2 test\": r2_glm_test,\n",
    "        \"rmse test\": pred_glm_test\n",
    "    }\n",
    "results_glm_modelx1 = pd.concat([pd.DataFrame(results_glm_modelx1), pd.DataFrame(pd.DataFrame(results_glm_modelx1).mean(), columns=[\"Average\"]).T])\n",
    "results_glm_modelx1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4922fb",
   "metadata": {},
   "source": [
    "### comparing all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing all models:\n",
    "\n",
    "model_comparison = pd.DataFrame({'model': ['OLS', 'LASSO', \"CART\", 'GBM', 'RF', \"GLM1\"],\n",
    "    'RMSE': [np.mean(rmse_modelx1_train), np.mean(rmse_lasso_train),\n",
    "            np.mean(rmse_cart_train), np.mean(rmse_gbm_train), np.mean(rmse_rf_train),\n",
    "            np.mean(rmse_glm_train)],\n",
    "    \"R2\": [np.mean(r2_modelx1_train), np.mean(r2_lasso_train),\n",
    "            np.mean(r2_cart_train), np.mean(r2_gbm_train), np.mean(r2_rf_train),\n",
    "            np.mean(r2_glm_train)]\n",
    "})\n",
    "\n",
    "print(\"The Random Forest model works best in both RMSE and R2\")\n",
    "model_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
