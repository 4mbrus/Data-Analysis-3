{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991f0550",
   "metadata": {},
   "source": [
    "### PART I: Probability prediction\n",
    "- Predict probabilities.\n",
    "- Look at cross-validated performance and pick your favorite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fec2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from statsmodels.tools.eval_measures import mse,rmse\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV, Lasso\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import patsy\n",
    "from stargazer.stargazer import Stargazer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54199ddf",
   "metadata": {},
   "source": [
    "# PART I: Probability prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4966b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the clean dataset\n",
    "firms_df = pd.read_csv(\"bisnode_firms_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3625ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawvars = [\"curr_assets\", \"curr_liab\", \"extra_exp\", \"extra_inc\", \"extra_profit_loss\", \"fixed_assets\",\n",
    "              \"inc_bef_tax\", \"intang_assets\", \"inventories\", \"liq_assets\", \"material_exp\", \"personnel_exp\",\n",
    "              \"profit_loss_year\", \"sales\", \"share_eq\", \"subscribed_cap\"]\n",
    "\n",
    "qualityvars = [\"balsheet_flag\", \"balsheet_length\", \"balsheet_notfullyear\"]\n",
    "\n",
    "engvar = [\"total_assets_bs\", \"fixed_assets_bs\", \"liq_assets_bs\", \"curr_assets_bs\",\n",
    "            \"share_eq_bs\", \"subscribed_cap_bs\", \"intang_assets_bs\", \"extra_exp_pl\",\n",
    "            \"extra_inc_pl\", \"extra_profit_loss_pl\", \"inc_bef_tax_pl\", \"inventories_pl\",\n",
    "            \"material_exp_pl\", \"profit_loss_year_pl\", \"personnel_exp_pl\"]\n",
    "\n",
    "engvar2 = [\"extra_profit_loss_pl_quad\", \"inc_bef_tax_pl_quad\",\n",
    "             \"profit_loss_year_pl_quad\", \"share_eq_bs_quad\"]\n",
    "\n",
    "engvar3 = []\n",
    "for col in firms_df.columns:\n",
    "    if col.endswith('flag_low') or col.endswith('flag_high') or col.endswith('flag_error') or col.endswith('flag_zero'):\n",
    "        engvar3.append(col)\n",
    "\n",
    "d1 =  [\"d1_sales_mil_log_mod\", \"d1_sales_mil_log_mod_sq\",\n",
    "         \"flag_low_d1_sales_mil_log\", \"flag_high_d1_sales_mil_log\"]\n",
    "\n",
    "hr = [\"female\", \"ceo_age\", \"flag_high_ceo_age\", \"flag_low_ceo_age\",\n",
    "        \"flag_miss_ceo_age\", \"ceo_count\", \"labor_avg_mod\",\n",
    "        \"flag_miss_labor_avg\", \"foreign_management\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663b4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = rawvars + qualityvars + engvar + engvar2 + engvar3 + d1 + hr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6c93f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cb23a894-067b-4d74-8077-f50968a7863c",
       "rows": [
        [
         "curr_assets",
         "0"
        ],
        [
         "curr_liab",
         "0"
        ],
        [
         "extra_exp",
         "0"
        ],
        [
         "extra_inc",
         "0"
        ],
        [
         "extra_profit_loss",
         "0"
        ],
        [
         "fixed_assets",
         "0"
        ],
        [
         "inc_bef_tax",
         "0"
        ],
        [
         "intang_assets",
         "0"
        ],
        [
         "inventories",
         "0"
        ],
        [
         "liq_assets",
         "0"
        ],
        [
         "material_exp",
         "0"
        ],
        [
         "personnel_exp",
         "0"
        ],
        [
         "profit_loss_year",
         "0"
        ],
        [
         "sales",
         "0"
        ],
        [
         "share_eq",
         "0"
        ],
        [
         "subscribed_cap",
         "0"
        ],
        [
         "balsheet_flag",
         "0"
        ],
        [
         "balsheet_length",
         "0"
        ],
        [
         "balsheet_notfullyear",
         "0"
        ],
        [
         "total_assets_bs",
         "0"
        ],
        [
         "fixed_assets_bs",
         "0"
        ],
        [
         "liq_assets_bs",
         "0"
        ],
        [
         "curr_assets_bs",
         "0"
        ],
        [
         "share_eq_bs",
         "0"
        ],
        [
         "subscribed_cap_bs",
         "0"
        ],
        [
         "intang_assets_bs",
         "0"
        ],
        [
         "extra_exp_pl",
         "326"
        ],
        [
         "extra_inc_pl",
         "315"
        ],
        [
         "extra_profit_loss_pl",
         "309"
        ],
        [
         "inc_bef_tax_pl",
         "1"
        ],
        [
         "inventories_pl",
         "303"
        ],
        [
         "material_exp_pl",
         "0"
        ],
        [
         "profit_loss_year_pl",
         "2"
        ],
        [
         "personnel_exp_pl",
         "201"
        ],
        [
         "extra_profit_loss_pl_quad",
         "309"
        ],
        [
         "inc_bef_tax_pl_quad",
         "1"
        ],
        [
         "profit_loss_year_pl_quad",
         "2"
        ],
        [
         "share_eq_bs_quad",
         "0"
        ],
        [
         "extra_exp_pl_flag_high",
         "326"
        ],
        [
         "extra_inc_pl_flag_high",
         "315"
        ],
        [
         "inventories_pl_flag_high",
         "303"
        ],
        [
         "material_exp_pl_flag_high",
         "0"
        ],
        [
         "personnel_exp_pl_flag_high",
         "201"
        ],
        [
         "curr_liab_bs_flag_high",
         "0"
        ],
        [
         "liq_assets_bs_flag_high",
         "0"
        ],
        [
         "subscribed_cap_bs_flag_high",
         "0"
        ],
        [
         "extra_exp_pl_flag_error",
         "326"
        ],
        [
         "extra_inc_pl_flag_error",
         "315"
        ],
        [
         "inventories_pl_flag_error",
         "303"
        ],
        [
         "material_exp_pl_flag_error",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 78
       }
      },
      "text/plain": [
       "curr_assets            0\n",
       "curr_liab              0\n",
       "extra_exp              0\n",
       "extra_inc              0\n",
       "extra_profit_loss      0\n",
       "                      ..\n",
       "flag_miss_ceo_age      0\n",
       "ceo_count              0\n",
       "labor_avg_mod          0\n",
       "flag_miss_labor_avg    0\n",
       "foreign_management     0\n",
       "Length: 78, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[all_vars].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5f52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "firms_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c7095",
   "metadata": {},
   "source": [
    "### Dealing with categorical variables\n",
    "To avoide multicolinearity, we drop the first values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6b1a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "comp_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "begin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "end",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "amort",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curr_assets",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curr_liab",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_exp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_inc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_profit_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fixed_assets",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inc_bef_tax",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intang_assets",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventories",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "liq_assets",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "material_exp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "personnel_exp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "profit_loss_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "share_eq",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "subscribed_cap",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tang_assets",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "balsheet_flag",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "balsheet_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "balsheet_notfullyear",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "founded_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ceo_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "foreign",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "female",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "birth_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inoffice_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "origin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nace_main",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ind2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ind",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "urban_m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "region_m",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "founded_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sales_growth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ln_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sales_mil",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sales_mil_log",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d1_sales_mil_log",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "new",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_fast_growing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ind2_cat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "foreign_management",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gender_m",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "m_region_loc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "flag_asset_problem",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_assets_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_exp_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_inc_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_profit_loss_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inc_bef_tax_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventories_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "material_exp_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "profit_loss_year_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "personnel_exp_pl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intang_assets_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curr_liab_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fixed_assets_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "liq_assets_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curr_assets_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "share_eq_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "subscribed_cap_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tang_assets_bs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_exp_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_inc_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventories_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "material_exp_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "personnel_exp_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curr_liab_bs_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "liq_assets_bs_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "subscribed_cap_bs_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_exp_pl_flag_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_inc_pl_flag_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventories_pl_flag_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "material_exp_pl_flag_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "personnel_exp_pl_flag_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curr_liab_bs_flag_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "liq_assets_bs_flag_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_profit_loss_pl_flag_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inc_bef_tax_pl_flag_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "profit_loss_year_pl_flag_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "share_eq_bs_flag_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_profit_loss_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inc_bef_tax_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "profit_loss_year_pl_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "share_eq_bs_flag_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_profit_loss_pl_flag_zero",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inc_bef_tax_pl_flag_zero",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "profit_loss_year_pl_flag_zero",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "share_eq_bs_flag_zero",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra_profit_loss_pl_quad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inc_bef_tax_pl_quad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "profit_loss_year_pl_quad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "share_eq_bs_quad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ceo_age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flag_low_ceo_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flag_high_ceo_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flag_miss_ceo_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ceo_young",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "labor_avg_mod",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flag_miss_labor_avg",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales_mil_log_sq",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flag_low_d1_sales_mil_log",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flag_high_d1_sales_mil_log",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "d1_sales_mil_log_mod",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d1_sales_mil_log_mod_sq",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9e2649cc-db98-4be4-b708-7299167c2ed5",
       "rows": [
        [
         "0",
         "2013",
         "1002029.0",
         "2013-01-01",
         "2013-12-31",
         "14255.5556640625",
         "217103.703125",
         "161174.078125",
         "0.0",
         "0.0",
         "0.0",
         "65177.77734375",
         "16588.888671875",
         "0.0",
         "677.7777709960938",
         "31507.408203125",
         "283011.125",
         "35944.4453125",
         "11777.77734375",
         "358062.96875",
         "104922.21875",
         "11111.111328125",
         "65177.77734375",
         "0.0",
         "364.0",
         "0.0",
         "2006.0",
         "1.0",
         "0.0",
         "0.0",
         "1979.0",
         "3802.0",
         "male",
         "Domestic",
         "2711.0",
         "27.0",
         "2.0",
         "3.0",
         "East",
         "2006-07-03",
         "-0.6849465179679237",
         "12.78846414027907",
         "0.35806296875",
         "-1.0270464176852043",
         "-1.1550128703394011",
         "7.0",
         "0.0",
         "0",
         "27.0",
         "49.0",
         "0.0",
         "male",
         "East",
         "0.0",
         "282281.48046875",
         "0.0",
         "0.0",
         "0.0",
         "0.0463295289367311",
         "0.001892901054142",
         "0.7903948458786273",
         "0.0328930338282852",
         "0.1003858216279172",
         "0.0",
         "0.5709693666667686",
         "0.2308963989969066",
         "0.1116169865299152",
         "0.7691036010030934",
         "0.3716935966743855",
         "0.0393618147023819",
         "0.2308963989969066",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0021464252514994",
         "0.0010819516744287",
         "0.1381561298087407",
         "34.0",
         "0",
         "0",
         "0",
         "1",
         "0.4375",
         "0",
         "1.0548243440800116",
         "0",
         "0",
         "-1.1550128703394011",
         "1.3340547306496622"
        ],
        [
         "1",
         "2013",
         "1011889.0",
         "2013-01-01",
         "2013-12-31",
         "66125.9296875",
         "235114.8125",
         "16555.5546875",
         "0.0",
         "0.0",
         "0.0",
         "938029.625",
         "65344.4453125",
         "0.0",
         "15022.22265625",
         "213670.375",
         "206200.0",
         "106466.65625",
         "64248.1484375",
         "442033.34375",
         "1132177.75",
         "17481.482421875",
         "938029.625",
         "0.0",
         "364.0",
         "0.0",
         "1992.0",
         "1.0",
         "0.0",
         "0.0",
         "1946.0",
         "6198.0",
         "male",
         "Domestic",
         "5510.0",
         "55.0",
         "3.0",
         "2.0",
         "West",
         "1992-11-09",
         "0.0192929001559594",
         "12.999140596562922",
         "0.44203334375",
         "-0.8163699614013518",
         "0.0191091517563746",
         "21.0",
         "0.0",
         "0",
         "55.0",
         "441.0",
         "0.0",
         "male",
         "West",
         "0.0",
         "1173144.4375",
         "0.0",
         "0.0",
         "0.0",
         "0.1478269597450475",
         "0.0339843653621435",
         "0.4664806465745266",
         "0.1453468371694528",
         "0.2408566180704552",
         "0.0",
         "0.014112119665998",
         "0.7995857926914477",
         "0.1821347552525901",
         "0.2004142073085523",
         "0.9650795876530762",
         "0.0149013896866173",
         "0.7995857926914477",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0218528100274638",
         "0.0211257030751634",
         "0.9313786105046316",
         "67.0",
         "0",
         "0",
         "0",
         "0",
         "1.5833333730697632",
         "0",
         "0.6664599138784446",
         "0",
         "0",
         "0.0191091517563746",
         "0.0003651596808481"
        ],
        [
         "2",
         "2013",
         "1014183.0",
         "2013-01-01",
         "2013-12-31",
         "6970.37060546875",
         "209562.96875",
         "5703.70361328125",
         "0.0",
         "0.0",
         "0.0",
         "112948.1484375",
         "7522.22216796875",
         "0.0",
         "0.0",
         "12596.2958984375",
         "61344.4453125",
         "61625.92578125",
         "6537.037109375",
         "116211.109375",
         "316414.8125",
         "11111.111328125",
         "112948.1484375",
         "0.0",
         "364.0",
         "0.0",
         "2001.0",
         "1.0",
         "0.0",
         "0.0",
         "1946.0",
         "3594.0",
         "male",
         "Domestic",
         "5510.0",
         "55.0",
         "3.0",
         "2.0",
         "Central",
         "2001-12-21",
         "-0.104205362679462",
         "11.663163724466854",
         "0.116211109375",
         "-2.152346833497421",
         "-0.1100440916964502",
         "12.0",
         "0.0",
         "0",
         "55.0",
         "144.0",
         "0.0",
         "male",
         "Central",
         "0.0",
         "322511.1171875",
         "0.0",
         "0.0",
         "0.0",
         "0.0647289420815646",
         "0.0",
         "0.5278707486953633",
         "0.0562513957962549",
         "0.5302928963735314",
         "0.0",
         "0.0176852930312019",
         "0.3502147442930928",
         "0.0390569354888759",
         "0.6497852557069071",
         "0.9810973812603312",
         "0.0344518707603659",
         "0.3502147442930928",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0041898359429985",
         "0.0031642195290269",
         "0.9625520715158794",
         "67.0",
         "0",
         "0",
         "0",
         "0",
         "0.8194444179534912",
         "0",
         "4.632596891666375",
         "0",
         "0",
         "-0.1100440916964502",
         "0.0121097021172967"
        ],
        [
         "3",
         "2013",
         "1022796.0",
         "2013-01-01",
         "2013-12-31",
         "503.7037048339844",
         "3859.25927734375",
         "8114.81494140625",
         "0.0",
         "0.0",
         "0.0",
         "922.2222290039062",
         "-5714.81494140625",
         "0.0",
         "814.8148193359375",
         "2848.148193359375",
         "33677.77734375",
         "11692.5927734375",
         "-7048.14794921875",
         "42518.51953125",
         "-3333.333251953125",
         "3703.70361328125",
         "922.2222290039062",
         "0.0",
         "364.0",
         "0.0",
         "2001.0",
         "1.0",
         "0.0",
         "0.0",
         "1969.0",
         "5201.0",
         "male",
         "Domestic",
         "5630.0",
         "56.0",
         "3.0",
         "1.0",
         "Central",
         "2001-02-01",
         "0.6292932186858409",
         "10.657695013675918",
         "0.04251851953125",
         "-3.1578155442883573",
         "0.4881463126152692",
         "12.0",
         "0.0",
         "1",
         "56.0",
         "144.0",
         "0.0",
         "male",
         "Central",
         "0.0",
         "4781.481506347656",
         "0.0",
         "0.0",
         "0.0",
         "-0.134407665281149",
         "0.0191637627160811",
         "0.7920731416576655",
         "-0.1657665418956684",
         "0.2749999977032067",
         "0.0",
         "1.0",
         "0.1928737417011045",
         "0.5956622836621486",
         "0.8071262582988954",
         "-0.6971339840022299",
         "0.7745933155580332",
         "0.1928737417011045",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0180654204863294",
         "0.0274785464120484",
         "0.4859957916508213",
         "44.0",
         "0",
         "0",
         "0",
         "0",
         "0.0833333358168602",
         "0",
         "9.971799011749177",
         "0",
         "0",
         "0.4881463126152692",
         "0.2382868225198841"
        ],
        [
         "4",
         "2013",
         "1035705.0",
         "2013-01-01",
         "2013-12-31",
         "244.44444274902344",
         "2392.592529296875",
         "9733.3330078125",
         "0.0",
         "0.0",
         "0.0",
         "1244.4444580078125",
         "-6311.111328125",
         "0.0",
         "1211.111083984375",
         "907.4074096679688",
         "23892.591796875",
         "4385.18505859375",
         "-6325.92578125",
         "22192.591796875",
         "-6029.62939453125",
         "11111.111328125",
         "1244.4444580078125",
         "0.0",
         "364.0",
         "0.0",
         "2011.0",
         "1.0",
         "0.0",
         "0.0",
         "1973.0",
         "1886.0",
         "male",
         "Domestic",
         "5630.0",
         "56.0",
         "3.0",
         "2.0",
         "East",
         "2011-10-26",
         "-0.0763064866289459",
         "10.00751380932572",
         "0.022192591796875",
         "-3.8079967486385553",
         "-0.0793749578494402",
         "2.0",
         "0.0",
         "0",
         "56.0",
         "4.0",
         "0.0",
         "male",
         "East",
         "0.0",
         "3637.036987304688",
         "0.0",
         "0.0",
         "0.0",
         "-0.2843791922047466",
         "0.0545727644192921",
         "1.0",
         "-0.2850467326732325",
         "0.1975967971082692",
         "0.0",
         "1.0",
         "0.3421588678783378",
         "0.2494908390635929",
         "0.6578411321216622",
         "-1.0",
         "1.0",
         "0.3421588678783378",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0808715249590242",
         "0.0812516398076852",
         "1.0",
         "40.0",
         "0",
         "0",
         "0",
         "0",
         "0.2222222238779068",
         "0",
         "14.50083923764181",
         "0",
         "0",
         "-0.0793749578494402",
         "0.0063003839336004"
        ]
       ],
       "shape": {
        "columns": 113,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>comp_id</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>amort</th>\n",
       "      <th>curr_assets</th>\n",
       "      <th>curr_liab</th>\n",
       "      <th>extra_exp</th>\n",
       "      <th>extra_inc</th>\n",
       "      <th>extra_profit_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_high_ceo_age</th>\n",
       "      <th>flag_miss_ceo_age</th>\n",
       "      <th>ceo_young</th>\n",
       "      <th>labor_avg_mod</th>\n",
       "      <th>flag_miss_labor_avg</th>\n",
       "      <th>sales_mil_log_sq</th>\n",
       "      <th>flag_low_d1_sales_mil_log</th>\n",
       "      <th>flag_high_d1_sales_mil_log</th>\n",
       "      <th>d1_sales_mil_log_mod</th>\n",
       "      <th>d1_sales_mil_log_mod_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>1002029.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>14255.555664</td>\n",
       "      <td>217103.703125</td>\n",
       "      <td>161174.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1.054824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.155013</td>\n",
       "      <td>1.334055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1011889.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>66125.929688</td>\n",
       "      <td>235114.812500</td>\n",
       "      <td>16555.554688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019109</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1014183.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>6970.370605</td>\n",
       "      <td>209562.968750</td>\n",
       "      <td>5703.703613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0</td>\n",
       "      <td>4.632597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.110044</td>\n",
       "      <td>0.012110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>1022796.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>503.703705</td>\n",
       "      <td>3859.259277</td>\n",
       "      <td>8114.814941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>9.971799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488146</td>\n",
       "      <td>0.238287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>1035705.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>244.444443</td>\n",
       "      <td>2392.592529</td>\n",
       "      <td>9733.333008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>14.500839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.079375</td>\n",
       "      <td>0.006300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    comp_id       begin         end         amort    curr_assets  \\\n",
       "0  2013  1002029.0  2013-01-01  2013-12-31  14255.555664  217103.703125   \n",
       "1  2013  1011889.0  2013-01-01  2013-12-31  66125.929688  235114.812500   \n",
       "2  2013  1014183.0  2013-01-01  2013-12-31   6970.370605  209562.968750   \n",
       "3  2013  1022796.0  2013-01-01  2013-12-31    503.703705    3859.259277   \n",
       "4  2013  1035705.0  2013-01-01  2013-12-31    244.444443    2392.592529   \n",
       "\n",
       "       curr_liab  extra_exp  extra_inc  extra_profit_loss  ...  \\\n",
       "0  161174.078125        0.0        0.0                0.0  ...   \n",
       "1   16555.554688        0.0        0.0                0.0  ...   \n",
       "2    5703.703613        0.0        0.0                0.0  ...   \n",
       "3    8114.814941        0.0        0.0                0.0  ...   \n",
       "4    9733.333008        0.0        0.0                0.0  ...   \n",
       "\n",
       "   flag_high_ceo_age  flag_miss_ceo_age  ceo_young  labor_avg_mod  \\\n",
       "0                  0                  0          1       0.437500   \n",
       "1                  0                  0          0       1.583333   \n",
       "2                  0                  0          0       0.819444   \n",
       "3                  0                  0          0       0.083333   \n",
       "4                  0                  0          0       0.222222   \n",
       "\n",
       "   flag_miss_labor_avg  sales_mil_log_sq  flag_low_d1_sales_mil_log  \\\n",
       "0                    0          1.054824                          0   \n",
       "1                    0          0.666460                          0   \n",
       "2                    0          4.632597                          0   \n",
       "3                    0          9.971799                          0   \n",
       "4                    0         14.500839                          0   \n",
       "\n",
       "   flag_high_d1_sales_mil_log  d1_sales_mil_log_mod  d1_sales_mil_log_mod_sq  \n",
       "0                           0             -1.155013                 1.334055  \n",
       "1                           0              0.019109                 0.000365  \n",
       "2                           0             -0.110044                 0.012110  \n",
       "3                           0              0.488146                 0.238287  \n",
       "4                           0             -0.079375                 0.006300  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09051331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "ind2_cat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "88865a53-e0c7-4267-aedc-137921884da8",
       "rows": [
        [
         "26.0",
         "735"
        ],
        [
         "27.0",
         "441"
        ],
        [
         "28.0",
         "1389"
        ],
        [
         "29.0",
         "179"
        ],
        [
         "30.0",
         "104"
        ],
        [
         "33.0",
         "1382"
        ],
        [
         "55.0",
         "1299"
        ],
        [
         "56.0",
         "8039"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "ind2_cat\n",
       "26.0     735\n",
       "27.0     441\n",
       "28.0    1389\n",
       "29.0     179\n",
       "30.0     104\n",
       "33.0    1382\n",
       "55.0    1299\n",
       "56.0    8039\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[\"ind2_cat\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1810b18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "urban_m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "57a296c2-eb94-49f9-bb71-0342c605d092",
       "rows": [
        [
         "1.0",
         "4278"
        ],
        [
         "2.0",
         "3872"
        ],
        [
         "3.0",
         "5418"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "urban_m\n",
       "1.0    4278\n",
       "2.0    3872\n",
       "3.0    5418\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[\"urban_m\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f83d539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "m_region_loc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "445f4d57-91cf-4b09-addc-b2e758376134",
       "rows": [
        [
         "Central",
         "7964"
        ],
        [
         "East",
         "3404"
        ],
        [
         "West",
         "2200"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "m_region_loc\n",
       "Central    7964\n",
       "East       3404\n",
       "West       2200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firms_df[\"m_region_loc\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e17643",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2_catmat = patsy.dmatrix(\"0 + C(ind2_cat, Treatment(reference=26))\", firms_df, return_type=\"dataframe\")\n",
    "m_region_locmat = patsy.dmatrix(\"0 + C(m_region_loc, Treatment(reference='Central'))\", firms_df, return_type=\"dataframe\")\n",
    "urban_mmat = patsy.dmatrix(\"0 + C(urban_m, Treatment(reference=1))\", firms_df, return_type=\"dataframe\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f26bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X1\n",
    "basevars = firms_df[[\"sales_mil_log\", \"sales_mil_log_sq\", \"d1_sales_mil_log_mod\", \"profit_loss_year_pl\"]]\n",
    "X1 = pd.concat([basevars, ind2_catmat], axis=1)\n",
    "\n",
    "# Define X2\n",
    "X2additional_vars = firms_df[[\"fixed_assets_bs\", \"share_eq_bs\",\"curr_liab_bs\", \"curr_liab_bs_flag_high\", \\\n",
    "                          \"curr_liab_bs_flag_error\",  \"age\", \"foreign_management\"]]\n",
    "X2 = pd.concat([X1, X2additional_vars], axis=1)\n",
    "\n",
    "# Define X3\n",
    "firm = pd.concat([firms_df[[\"age\", \"age2\", \"new\"]], ind2_catmat, m_region_locmat, urban_mmat], axis=1)\n",
    "X3 = pd.concat([firms_df[[\"sales_mil_log\", \"sales_mil_log_sq\"] + engvar + d1], firm], axis=1)\n",
    "\n",
    "# Define X4\n",
    "X4 = pd.concat([firms_df[[\"sales_mil_log\", \"sales_mil_log_sq\"] + engvar + d1 \\\n",
    "                                 + engvar2 + engvar3 + hr + qualityvars], firm], axis=1)\n",
    "\n",
    "# Define X5\n",
    "\n",
    "#Creat matrix for interactions1 variables\n",
    "int1mat = patsy.dmatrix(\"0 + C(ind2_cat):age + C(ind2_cat):age2 + C(ind2_cat):d1_sales_mil_log_mod \\\n",
    "                + C(ind2_cat):sales_mil_log + C(ind2_cat):ceo_age + C(ind2_cat):foreign_management \\\n",
    "                + C(ind2_cat):female + C(ind2_cat):C(urban_m) + C(ind2_cat):labor_avg_mod\", \n",
    "                        firms_df, return_type=\"dataframe\")\n",
    "\n",
    "#Drop first level to get k-1 dummies out of k categorical levels \n",
    "for col in int1mat.columns:\n",
    "    if col.startswith('C(ind2_cat)[26]') or col.endswith('C(urban_m)[1]'):\n",
    "        int1mat = int1mat.drop([col], axis=1)\n",
    "        \n",
    "#Creat matrix for interactions2 variables        \n",
    "int2mat = patsy.dmatrix(\"0 + sales_mil_log:age + sales_mil_log:female + sales_mil_log:profit_loss_year_pl \\\n",
    "                + sales_mil_log:foreign_management\", \n",
    "                        firms_df, return_type=\"dataframe\")\n",
    "\n",
    "X5 = pd.concat([X4, int1mat, int2mat], axis=1)\n",
    "\n",
    "# Define logitvars for LASSO\n",
    "logitvars = pd.concat([X4, int1mat, int2mat], axis=1)\n",
    "\n",
    "# Define rfvars for RF (no interactions, no modified features)\n",
    "rfvars  = pd.concat([firms_df[[\"sales_mil\", \"d1_sales_mil_log\"] + rawvars + hr + qualityvars], firm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c268b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = firms_df[\"is_fast_growing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76268534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2318691037735849)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62833502",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2267173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "\n",
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    \n",
    "def create_coef_matrix(X, model):\n",
    "    coef_matrix = pd.concat(\n",
    "        [pd.DataFrame(X.columns),pd.DataFrame(model.coef_.flatten())], axis = 1\n",
    "    )\n",
    "    coef_matrix.columns = ['variable', 'coefficient']\n",
    "    coef_matrix.iloc[-1] = ['Intercept', model.intercept_.flatten()[0]]\n",
    "    return coef_matrix\n",
    "\n",
    "def cv_summary(lambdas, C_values, model):\n",
    "    d = {'lambdas': lambdas, \n",
    "         'C_values': C_values, \n",
    "         'mean_cv_score': model.scores_[1].mean(axis = 0)}\n",
    "    return(pd.DataFrame(data=d))\n",
    "\n",
    "\"\"\"def create_roc_plot(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    all_coords = pd.DataFrame({\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'thresholds': thresholds\n",
    "    })\n",
    "    \n",
    "    plot = ggplot(all_coords, aes(x = 'fpr', y = 'tpr')) \\\n",
    "        + geom_line(color=color[0], size = 0.7) \\\n",
    "        + geom_area(position = 'identity', fill = 'mediumaquamarine', alpha = 0.3) \\\n",
    "        + xlab(\"False Positive Rate (1-Specifity)\") \\\n",
    "        + ylab(\"True Positive Rate (Sensitivity)\") \\\n",
    "        + geom_abline(intercept = 0, slope = 1,  linetype = \"dotted\", color = \"black\") \\\n",
    "        + scale_y_continuous(limits = (0, 1), breaks = seq(0, 1, .1), expand = (0, 0.01)) \\\n",
    "        + scale_x_continuous(limits = (0, 1), breaks = seq(0, 1, .1), expand = (0.01, 0)) \\\n",
    "        + theme_bw()\n",
    "    return(plot)\n",
    "\"\"\"\n",
    "\n",
    "def create_roc_plot(y_true, y_pred): # this is pretty important!\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred) # on x false positive and on y true positive\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    # Plot ROC curve line\n",
    "    ax.plot(fpr, tpr, color='k', linewidth=0.7)\n",
    "    \n",
    "    # Fill area under curve\n",
    "    ax.fill_between(fpr, tpr, alpha=0.3, color='white')\n",
    "    \n",
    "    # Add diagonal dotted line\n",
    "    ax.plot([0, 1], [0, 1], linestyle=':', color='black')\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax.set_xlabel('False Positive Rate (1-Specificity)')\n",
    "    ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "    \n",
    "    # Set axis limits and ticks\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    \n",
    "    # Style similar to theme_bw()\n",
    "    ax.grid(True, linestyle='-', alpha=0.2)\n",
    "    ax.set_facecolor('white')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def sigmoid_array(x):\n",
    "    return(1 / (1 + np.exp(-x)))\n",
    "\n",
    "def generate_fold_prediction(model, X, fold, param_index):\n",
    "    fold_coef = model.coefs_paths_[1][fold,param_index,:]\n",
    "    return(sigmoid_array(np.dot(X, np.transpose(fold_coef)[:-1]) +  np.transpose(fold_coef)[-1]))\n",
    "\n",
    "\"\"\"def create_loss_plot(all_coords, optimal_threshold, curr_exp_loss):\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['loss'] = (all_coords_copy.false_pos*FP + all_coords_copy.false_neg*FN)/all_coords_copy.n\n",
    "    \n",
    "    t = optimal_threshold\n",
    "    l = curr_exp_loss\n",
    "    \n",
    "    plot = ggplot(all_coords_copy, aes(x = 'thresholds', y = 'loss')) + \\\n",
    "        geom_line(color=color[0], size=0.7) + \\\n",
    "        scale_x_continuous(breaks = seq(0, 1.1, by = 0.1)) + \\\n",
    "        coord_cartesian(xlim=(0,1))+ \\\n",
    "        geom_vline(xintercept = t , color = color[0] ) + \\\n",
    "        annotate(geom = \"text\", x = t - 0.01, y= max(all_coords_copy.loss) - 0.4,\n",
    "                 label=\"best threshold: \" + str(round(t,2)),\n",
    "                 colour=color[1], angle=90, size = 7) +\\\n",
    "        annotate(geom = \"text\", x = t + 0.06, y= l,\\\n",
    "                 label= str(round(l, 2)), size = 7) +\\\n",
    "        theme_bw()\n",
    "    return(plot)\"\"\"\n",
    "\n",
    "def create_loss_plot(all_coords, optimal_threshold, curr_exp_loss): # what is optimal threshold here?\n",
    "    # Create copy and calculate loss\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['loss'] = (all_coords_copy.false_pos*FP + all_coords_copy.false_neg*FN)/all_coords_copy.n\n",
    "    \n",
    "    t = optimal_threshold\n",
    "    l = curr_exp_loss\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    # Plot loss line\n",
    "    ax.plot(all_coords_copy['thresholds'], all_coords_copy['loss'], \n",
    "            color= 'k', linewidth=0.7)\n",
    "\n",
    "    # Add vertical line at optimal threshold\n",
    "    ax.axvline(x=t, color = 'k')\n",
    "\n",
    "    # Add annotations\n",
    "    ax.text(t - 0.04, max(all_coords_copy.loss) - 0.5,\n",
    "            f\"best threshold: {t:.2f}\", \n",
    "            color = 'k', \n",
    "            rotation=90, \n",
    "            fontsize = 9)\n",
    "    \n",
    "    ax.text(t + 0.06, l,\n",
    "            f\"{l:.2f}\",\n",
    "            fontsize = 9)\n",
    "\n",
    "    # Set x-axis ticks and limits\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "    # Style similar to theme_bw()\n",
    "    ax.grid(True, linestyle='-', alpha=0.2)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xlabel('threshold')\n",
    "    ax.set_ylabel('loss')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"def create_roc_plot_with_optimal(all_coords, optimal_threshold):\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['sp'] = all_coords_copy.true_neg/all_coords_copy.neg\n",
    "    all_coords_copy['se'] = all_coords_copy.true_pos/all_coords_copy.pos\n",
    "    \n",
    "    best_coords = all_coords_copy[all_coords_copy.thresholds == optimal_threshold]\n",
    "    sp = best_coords.sp.values[0]\n",
    "    se = best_coords.se.values[0]\n",
    "\n",
    "    plot = ggplot(all_coords_copy, aes(x = 'sp', y = 'se')) +\\\n",
    "        geom_line(color=color[0], size=0.7) +\\\n",
    "        scale_y_continuous(breaks = seq(0, 1.1, by = 0.1)) +\\\n",
    "        scale_x_reverse(breaks = seq(0, 1.1, by = 0.1)) +\\\n",
    "        geom_point(data = pd.DataFrame({'sp': [sp], 'se': [se]})) +\\\n",
    "        annotate(geom = \"text\", x = sp, y = se + 0.03,\n",
    "                 label = str(round(sp, 2)) + ', ' + str(round(se, 2)), size = 7) +\\\n",
    "        theme_bw()\n",
    "    return(plot)\n",
    "\"\"\"\n",
    "def create_roc_plot_with_optimal(all_coords, optimal_threshold):\n",
    "    # Create copy and calculate metrics\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['sp'] = all_coords_copy.true_neg/all_coords_copy.neg\n",
    "    all_coords_copy['se'] = all_coords_copy.true_pos/all_coords_copy.pos\n",
    "    \n",
    "    # Get optimal point\n",
    "    best_coords = all_coords_copy[all_coords_copy.thresholds == optimal_threshold]\n",
    "    sp = best_coords.sp.values[0]\n",
    "    se = best_coords.se.values[0]\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    ax.plot(all_coords_copy['sp'], all_coords_copy['se'],\n",
    "            color='k', linewidth=0.9)\n",
    "    \n",
    "    # Add optimal point\n",
    "    ax.scatter([sp], [se], color='k', s = 100)\n",
    "    \n",
    "    # Add text annotation\n",
    "    ax.text(sp, se + 0.03,\n",
    "            f\"{sp:.2f}, {se:.2f}\",\n",
    "            fontsize = 9,\n",
    "            ha='center')\n",
    "    ax.text(sp - 0.02, se - 0.18,\n",
    "            'specificity (TNR) \\n& sensitivity (TPR) \\nat the best threshold',\n",
    "            fontsize = 9,\n",
    "            ha='center'\n",
    "           )\n",
    "    \n",
    "    # Set axis ticks and limits\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_xlabel('specificity')\n",
    "    ax.set_ylabel('sensitivity')\n",
    "    \n",
    "    # Reverse x-axis\n",
    "    ax.set_xlim(1, 0)\n",
    "    \n",
    "    # Style similar to theme_bw()\n",
    "    ax.grid(True, linestyle='-', alpha=0.2)\n",
    "    ax.set_facecolor('white')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26074ffe",
   "metadata": {},
   "source": [
    "### OLS X1:X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24865a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "# train - test split\n",
    "df_train, df_test=train_test_split(firms_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross-Validation for: OLS_Model_X1\n",
      "Running Cross-Validation for: OLS_Model_X2\n",
      "Running Cross-Validation for: OLS_Model_X3\n",
      "Running Cross-Validation for: OLS_Model_X4\n",
      "Running Cross-Validation for: OLS_Model_X5\n",
      "Calculation complete.\n"
     ]
    }
   ],
   "source": [
    "model_specs = {\n",
    "    \"OLS_Model_X1\": X1,\n",
    "    \"OLS_Model_X2\": X2, \n",
    "    \"OLS_Model_X3\": X3,\n",
    "    \"OLS_Model_X4\": X4,\n",
    "    \"OLS_Model_X5\": X5\n",
    "}\n",
    "\n",
    "results = {name: {\n",
    "    'rmse_test': [], 'r2_test': [], 'pred_test_mean': [],\n",
    "    'rmse_train': [], 'r2_train': [], 'pred_train_mean': []\n",
    "} for name in model_specs}\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through each Model \n",
    "for model_name, X_data in model_specs.items():\n",
    "    \n",
    "    print(f\"Running Cross-Validation for: {model_name}\")\n",
    "    \n",
    "    # Inner Loop: K-Fold Split\n",
    "    for train_index, test_index in k.split(firms_df):\n",
    "        \n",
    "        # Select data based on indices and add constant\n",
    "        X_train_fold = sm.add_constant(X_data.iloc[train_index])\n",
    "        X_test_fold = sm.add_constant(X_data.iloc[test_index])\n",
    "        \n",
    "        y_train_fold = y.iloc[train_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        # Fit OLS\n",
    "        model = sm.OLS(y_train_fold, X_train_fold).fit()\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_test = model.predict(X_test_fold)\n",
    "        y_pred_train = model.predict(X_train_fold)\n",
    "        \n",
    "        # --- Store Results into the Dictionary ---\n",
    "        \n",
    "        # Test Metrics\n",
    "        results[model_name]['rmse_test'].append(np.sqrt(mean_squared_error(y_test_fold, y_pred_test)))\n",
    "        results[model_name]['r2_test'].append(r2_score(y_test_fold, y_pred_test))\n",
    "        results[model_name]['pred_test_mean'].append(np.mean(y_pred_test))\n",
    "        \n",
    "        # Train Metrics\n",
    "        results[model_name]['rmse_train'].append(np.sqrt(mean_squared_error(y_train_fold, y_pred_train)))\n",
    "        results[model_name]['r2_train'].append(r2_score(y_train_fold, y_pred_train))\n",
    "        results[model_name]['pred_train_mean'].append(np.mean(y_pred_train))\n",
    "\n",
    "print(\"Calculation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd700e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Avg_RMSE_Test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Avg_R2_Test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pred_Test_Mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Avg_RMSE_Train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Avg_R2_Train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pred_Train_Mean",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1186fd34-c080-424e-838c-858a5fea4fa1",
       "rows": [
        [
         "0",
         "OLS_Model_X1",
         "0.347",
         "0.325",
         "0.232",
         "0.346",
         "0.326",
         "0.232"
        ],
        [
         "1",
         "OLS_Model_X2",
         "0.339",
         "0.353",
         "0.232",
         "0.339",
         "0.355",
         "0.232"
        ],
        [
         "2",
         "OLS_Model_X3",
         "0.278",
         "0.566",
         "0.232",
         "0.277",
         "0.57",
         "0.232"
        ],
        [
         "3",
         "OLS_Model_X4",
         "0.274",
         "0.578",
         "0.232",
         "0.272",
         "0.585",
         "0.232"
        ],
        [
         "4",
         "OLS_Model_X5",
         "0.274",
         "0.577",
         "0.232",
         "0.27",
         "0.59",
         "0.232"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg_RMSE_Test</th>\n",
       "      <th>Avg_R2_Test</th>\n",
       "      <th>Pred_Test_Mean</th>\n",
       "      <th>Avg_RMSE_Train</th>\n",
       "      <th>Avg_R2_Train</th>\n",
       "      <th>Pred_Train_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS_Model_X1</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLS_Model_X2</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLS_Model_X3</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OLS_Model_X4</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OLS_Model_X5</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Avg_RMSE_Test  Avg_R2_Test  Pred_Test_Mean  Avg_RMSE_Train  \\\n",
       "0  OLS_Model_X1          0.347        0.325           0.232           0.346   \n",
       "1  OLS_Model_X2          0.339        0.353           0.232           0.339   \n",
       "2  OLS_Model_X3          0.278        0.566           0.232           0.277   \n",
       "3  OLS_Model_X4          0.274        0.578           0.232           0.272   \n",
       "4  OLS_Model_X5          0.274        0.577           0.232           0.270   \n",
       "\n",
       "   Avg_R2_Train  Pred_Train_Mean  \n",
       "0         0.326            0.232  \n",
       "1         0.355            0.232  \n",
       "2         0.570            0.232  \n",
       "3         0.585            0.232  \n",
       "4         0.590            0.232  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_rows = []\n",
    "for name, metrics in results.items():\n",
    "    summary_rows.append({\n",
    "        'Model': name,\n",
    "        'Avg_RMSE_Test': np.mean(metrics['rmse_test']),\n",
    "        'Avg_R2_Test': np.mean(metrics['r2_test']),\n",
    "        'Pred_Test_Mean': np.mean(metrics['pred_test_mean']),\n",
    "        'Avg_RMSE_Train': np.mean(metrics['rmse_train']),\n",
    "        'Avg_R2_Train': np.mean(metrics['r2_train']),\n",
    "        'Pred_Train_Mean': np.mean(metrics['pred_train_mean'])\n",
    "\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3f983",
   "metadata": {},
   "source": [
    "### Logistic Regression with Cross-Validation for X1:X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c033b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train, index_holdout= train_test_split(\n",
    "    firms_df.index.values, train_size=round(0.8*len(firms_df.index)), random_state=42)\n",
    "\n",
    "y_train = y[index_train]\n",
    "y_holdout = y[index_holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0a102a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model_vars = [X1.loc[index_train], X2.loc[index_train], X3.loc[index_train], X4.loc[index_train], X5.loc[index_train]]\n",
    "\n",
    "logit_models = dict()\n",
    "CV_RMSE_folds = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "728ec222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-07 20:03:14.530214 Running regression 0...\n",
      "2026-02-07 20:03:14.660355 Running regression 1...\n",
      "2026-02-07 20:03:14.942590 Running regression 2...\n",
      "2026-02-07 20:03:17.441533 Running regression 3...\n",
      "2026-02-07 20:03:22.287772 Running regression 4...\n"
     ]
    }
   ],
   "source": [
    "#### runs for more than 3 minutes!!! ####\n",
    "import datetime\n",
    "logit_r2 = {}\n",
    "\n",
    "\n",
    "for i in range(len(logit_model_vars)):\n",
    "    print(datetime.datetime.now(), f'Running regression {i}...')\n",
    "    LRCV_brier = LogisticRegressionCV(\n",
    "        Cs = [1e20], \n",
    "        cv = k, # simply the number of folds\n",
    "        refit = True, \n",
    "        scoring = 'neg_brier_score', \n",
    "        solver = \"newton-cg\", \n",
    "        tol=1e-7, \n",
    "        random_state = 20250224)\n",
    "    logit_models['X'+str(i+1)] = LRCV_brier.fit(logit_model_vars[i], y_train)\n",
    "    \n",
    "    # Calculate RMSE on test for each fold\n",
    "    CV_RMSE_folds['X'+str(i+1)] = np.sqrt(-1*(logit_models['X'+str(i+1)].scores_[1])).flatten()\n",
    "    logit_r2['X'+str(i+1)] = logit_models['X'+str(i+1)].score(logit_model_vars[i], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dd92899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "X1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X5",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9c6bf9c3-7682-45a5-8515-6c614c3a2d9a",
       "rows": [
        [
         "0",
         "0.26815856036379626",
         "0.26675156574834885",
         "0.213990213384327",
         "0.24376969748935737",
         "0.20969470266213563"
        ],
        [
         "1",
         "0.2722579525656083",
         "0.27307371698285077",
         "0.19616127001160633",
         "0.23996121255168662",
         "0.19795550961958197"
        ],
        [
         "2",
         "0.28152253852109627",
         "0.27770522850633717",
         "0.2271612696375466",
         "0.24442021810104766",
         "0.21830525979512982"
        ],
        [
         "3",
         "0.2793619853329745",
         "0.2803018982053305",
         "0.2174753880336129",
         "0.2730362055047247",
         "0.22427739877244987"
        ],
        [
         "4",
         "0.2662505021775286",
         "0.2650492311361322",
         "0.20966340324987398",
         "0.23908363181187875",
         "0.21358145441888926"
        ],
        [
         "Average",
         "0.27351030779220076",
         "0.2725763281157999",
         "0.21289030886339333",
         "0.24805419309173898",
         "0.21276286505363734"
        ],
        [
         "R2",
         "-0.0745608991711656",
         "-0.07368437349462928",
         "-0.016377748220023646",
         "-0.017412207905810627",
         "-0.01562436954308803"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268159</td>\n",
       "      <td>0.266752</td>\n",
       "      <td>0.213990</td>\n",
       "      <td>0.243770</td>\n",
       "      <td>0.209695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272258</td>\n",
       "      <td>0.273074</td>\n",
       "      <td>0.196161</td>\n",
       "      <td>0.239961</td>\n",
       "      <td>0.197956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281523</td>\n",
       "      <td>0.277705</td>\n",
       "      <td>0.227161</td>\n",
       "      <td>0.244420</td>\n",
       "      <td>0.218305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279362</td>\n",
       "      <td>0.280302</td>\n",
       "      <td>0.217475</td>\n",
       "      <td>0.273036</td>\n",
       "      <td>0.224277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266251</td>\n",
       "      <td>0.265049</td>\n",
       "      <td>0.209663</td>\n",
       "      <td>0.239084</td>\n",
       "      <td>0.213581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.273510</td>\n",
       "      <td>0.272576</td>\n",
       "      <td>0.212890</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>0.212763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-0.074561</td>\n",
       "      <td>-0.073684</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.017412</td>\n",
       "      <td>-0.015624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1        X2        X3        X4        X5\n",
       "0        0.268159  0.266752  0.213990  0.243770  0.209695\n",
       "1        0.272258  0.273074  0.196161  0.239961  0.197956\n",
       "2        0.281523  0.277705  0.227161  0.244420  0.218305\n",
       "3        0.279362  0.280302  0.217475  0.273036  0.224277\n",
       "4        0.266251  0.265049  0.209663  0.239084  0.213581\n",
       "Average  0.273510  0.272576  0.212890  0.248054  0.212763\n",
       "R2      -0.074561 -0.073684 -0.016378 -0.017412 -0.015624"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse_folds = pd.DataFrame(CV_RMSE_folds)\n",
    "glm_model_overview = pd.concat([cv_rmse_folds, pd.DataFrame(cv_rmse_folds.mean(), columns = [\"Average\"]).T,\n",
    "                                pd.DataFrame(logit_r2, index= [\"R2\"])])\n",
    "glm_model_overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "603705c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### honestly, all of the models are kind of equally bad; any difference between them might just be random\n",
    "### still, going off the numbers, we'll want to pick X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa5187",
   "metadata": {},
   "source": [
    "### Lasso Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3152cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we normalize the lasso variables\n",
    "normalized_logitvars = pd.DataFrame(StandardScaler().fit_transform(logitvars.loc[index_train]))\n",
    "normalized_logitvars.columns = logitvars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d1227d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas=list(10**np.arange(-1,-4.01, -1/3))\n",
    "n_obs = normalized_logitvars.shape[0]*4/5\n",
    "Cs_values = [1/(l*n_obs) for l in lambdas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "556b369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.00115164916159941),\n",
       " np.float64(0.002481152904495904),\n",
       " np.float64(0.0053454818887193395),\n",
       " np.float64(0.011516491615994096),\n",
       " np.float64(0.024811529044959025),\n",
       " np.float64(0.053454818887193334),\n",
       " np.float64(0.1151649161599409),\n",
       " np.float64(0.24811529044959024),\n",
       " np.float64(0.5345481888719334),\n",
       " np.float64(1.1516491615994078)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs_values # the strength of the regularization -> supressing unimportant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99bca4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logLasso = LogisticRegressionCV(\n",
    "    Cs = Cs_values, \n",
    "    penalty = 'l1', # L1 makes it lasso\n",
    "    cv = k, \n",
    "    refit = True, \n",
    "    scoring = 'accuracy', \n",
    "    solver = 'liblinear',\n",
    "    random_state = 20250224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8de44e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logit_models[\"LASSO\"] = logLasso.fit(normalized_logitvars, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2448375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lambdas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "C_values",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_cv_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "362d906c-4652-42b8-be3e-bdc6fe865799",
       "rows": [
        [
         "0",
         "0.1",
         "0.00115164916159941",
         "0.8512060742039494"
        ],
        [
         "1",
         "0.046415888336127795",
         "0.002481152904495904",
         "0.9071300575028604"
        ],
        [
         "2",
         "0.021544346900318846",
         "0.0053454818887193395",
         "0.9393767445612143"
        ],
        [
         "3",
         "0.010000000000000005",
         "0.011516491615994096",
         "0.9538414415408812"
        ],
        [
         "4",
         "0.004641588833612782",
         "0.024811529044959025",
         "0.9647131967896889"
        ],
        [
         "5",
         "0.002154434690031887",
         "0.053454818887193334",
         "0.9701492442268954"
        ],
        [
         "6",
         "0.001000000000000001",
         "0.1151649161599409",
         "0.9722683806438877"
        ],
        [
         "7",
         "0.0004641588833612782",
         "0.24811529044959024",
         "0.9727290403241728"
        ],
        [
         "8",
         "0.00021544346900318867",
         "0.5345481888719334",
         "0.972729125230574"
        ],
        [
         "9",
         "0.00010000000000000021",
         "1.1516491615994078",
         "0.9730975765590408"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambdas</th>\n",
       "      <th>C_values</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.851206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046416</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.907130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.939377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.011516</td>\n",
       "      <td>0.953841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.024812</td>\n",
       "      <td>0.964713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.053455</td>\n",
       "      <td>0.970149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.115165</td>\n",
       "      <td>0.972268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.248115</td>\n",
       "      <td>0.972729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.534548</td>\n",
       "      <td>0.972729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.151649</td>\n",
       "      <td>0.973098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambdas  C_values  mean_cv_score\n",
       "0  0.100000  0.001152       0.851206\n",
       "1  0.046416  0.002481       0.907130\n",
       "2  0.021544  0.005345       0.939377\n",
       "3  0.010000  0.011516       0.953841\n",
       "4  0.004642  0.024812       0.964713\n",
       "5  0.002154  0.053455       0.970149\n",
       "6  0.001000  0.115165       0.972268\n",
       "7  0.000464  0.248115       0.972729\n",
       "8  0.000215  0.534548       0.972729\n",
       "9  0.000100  1.151649       0.973098"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_summary_lasso = cv_summary(lambdas, Cs_values, logit_models[\"LASSO\"])\n",
    "cv_summary_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96668365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refit with negative brier score so we have RMSE values for the same cv split\n",
    "#### takes \n",
    "\n",
    "logLasso_brier = LogisticRegressionCV(\n",
    "    Cs = Cs_values, \n",
    "    penalty = 'l1', \n",
    "    cv = k, \n",
    "    refit = True, \n",
    "    scoring = 'neg_brier_score', # now negative; before we optimized based on accuracy\n",
    "    solver = \"liblinear\", \n",
    "    random_state = 20250224)\n",
    "logLasso_brier_fitted = logLasso_brier.fit(normalized_logitvars, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35360e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.00010000000000000021)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda = cv_summary_lasso.sort_values('mean_cv_score', ascending = False).iloc[0,0]\n",
    "best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2d4e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_loglasso = {}\n",
    "\n",
    "for i, l in enumerate(lambdas):\n",
    "    if l == best_lambda:\n",
    "        best_lambda_i = i\n",
    "        CV_RMSE_folds['LASSO'] = np.sqrt(-1*(logLasso_brier_fitted.scores_[1][:,i])).tolist()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6536f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "X1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LASSO",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4dfb3d45-6a4d-4ee8-8bfa-aa027b172c98",
       "rows": [
        [
         "0",
         "0.26815856036379626",
         "0.26675156574834885",
         "0.213990213384327",
         "0.24376969748935737",
         "0.20969470266213563",
         "0.15144903484421232"
        ],
        [
         "1",
         "0.2722579525656083",
         "0.27307371698285077",
         "0.19616127001160633",
         "0.23996121255168662",
         "0.19795550961958197",
         "0.13275765881678203"
        ],
        [
         "2",
         "0.28152253852109627",
         "0.27770522850633717",
         "0.2271612696375466",
         "0.24442021810104766",
         "0.21830525979512982",
         "0.13736249181522286"
        ],
        [
         "3",
         "0.2793619853329745",
         "0.2803018982053305",
         "0.2174753880336129",
         "0.2730362055047247",
         "0.22427739877244987",
         "0.14266595706731258"
        ],
        [
         "4",
         "0.2662505021775286",
         "0.2650492311361322",
         "0.20966340324987398",
         "0.23908363181187875",
         "0.21358145441888926",
         "0.1308832129902907"
        ],
        [
         "Average",
         "0.27351030779220076",
         "0.2725763281157999",
         "0.21289030886339333",
         "0.24805419309173898",
         "0.21276286505363734",
         "0.1390236711067641"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>LASSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268159</td>\n",
       "      <td>0.266752</td>\n",
       "      <td>0.213990</td>\n",
       "      <td>0.243770</td>\n",
       "      <td>0.209695</td>\n",
       "      <td>0.151449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272258</td>\n",
       "      <td>0.273074</td>\n",
       "      <td>0.196161</td>\n",
       "      <td>0.239961</td>\n",
       "      <td>0.197956</td>\n",
       "      <td>0.132758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281523</td>\n",
       "      <td>0.277705</td>\n",
       "      <td>0.227161</td>\n",
       "      <td>0.244420</td>\n",
       "      <td>0.218305</td>\n",
       "      <td>0.137362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279362</td>\n",
       "      <td>0.280302</td>\n",
       "      <td>0.217475</td>\n",
       "      <td>0.273036</td>\n",
       "      <td>0.224277</td>\n",
       "      <td>0.142666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266251</td>\n",
       "      <td>0.265049</td>\n",
       "      <td>0.209663</td>\n",
       "      <td>0.239084</td>\n",
       "      <td>0.213581</td>\n",
       "      <td>0.130883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.273510</td>\n",
       "      <td>0.272576</td>\n",
       "      <td>0.212890</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>0.212763</td>\n",
       "      <td>0.139024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1        X2        X3        X4        X5     LASSO\n",
       "0        0.268159  0.266752  0.213990  0.243770  0.209695  0.151449\n",
       "1        0.272258  0.273074  0.196161  0.239961  0.197956  0.132758\n",
       "2        0.281523  0.277705  0.227161  0.244420  0.218305  0.137362\n",
       "3        0.279362  0.280302  0.217475  0.273036  0.224277  0.142666\n",
       "4        0.266251  0.265049  0.209663  0.239084  0.213581  0.130883\n",
       "Average  0.273510  0.272576  0.212890  0.248054  0.212763  0.139024"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglasso_overview = pd.DataFrame(CV_RMSE_folds)\n",
    "\n",
    "loglasso_overview = pd.concat([loglasso_overview, pd.DataFrame(loglasso_overview.mean(), columns = [\"Average\"]).T])\n",
    "loglasso_overview\n",
    "\n",
    "# TODO: one could add an R2 to this\n",
    "# but really, LASSO is gonna be worse regardless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48940ef",
   "metadata": {},
   "source": [
    "# PART II: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7ef7c",
   "metadata": {},
   "source": [
    "Think about the business problem, and define your loss function (like FP=X dollars, FN=Y dollars).\n",
    "\n",
    "Idea 1: We have some spare money and want to do some investments. Overall, riskier firms, thus firms with a higher probability to default also pay higher returns. On the other hand, we lose money when a risky firm defaults. The money lost from an unexpected default is about the same, as money lost from a risky firm that ends up well performing that we decided not to invest in.\n",
    "Therefore, a suggested loss function would be:\n",
    "FP = 0.5 FN = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea9dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3efcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb482ad",
   "metadata": {},
   "source": [
    "## MODELS WE CAN'T USE  :/\n",
    "\n",
    "My dumb ass forgot that we have binary outcome variables and calculated all the regular models.\n",
    "\n",
    "For now, I'm keeping them in the script in case that some  of the syntax might come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592f622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd06e45",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40da8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# define model\n",
    "model = Lasso()\n",
    "\n",
    "grid = dict()\n",
    "grid[\"alpha\"] = np.arange(0.05, 1, 0.05)\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring=\"neg_root_mean_squared_error\", cv = k, verbose= 3) # control your output with the 'verbose' option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c9d79de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.351 total time=   0.5s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.347 total time=   0.4s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.369 total time=   0.2s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.359 total time=   0.2s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.356 total time=   0.3s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.399 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.398 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.420 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.413 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.405 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.402 total time=   0.1s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.401 total time=   0.1s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.422 total time=   0.1s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.416 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.402 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.401 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.423 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.416 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.401 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.417 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.402 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.424 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.417 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.402 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.402 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.418 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.407 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.403 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.424 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.418 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.403 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.424 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.403 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.425 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.418 total time=   0.1s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.403 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.425 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.418 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.408 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.404 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.425 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.426 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.419 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.426 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.426 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.409 total time=   0.0s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.358 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.354 total time=   0.2s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.354 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.365 total time=   0.3s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.347 total time=   0.8s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.412 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.406 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.405 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.415 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.398 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.414 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.409 total time=   0.1s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.407 total time=   0.1s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.401 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.409 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.408 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.418 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.401 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.409 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.408 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.402 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.419 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.402 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.409 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.415 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.402 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.410 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.410 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.411 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.420 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.417 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.417 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.404 total time=   0.0s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.350 total time=   0.2s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.360 total time=   0.4s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.354 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.354 total time=   0.2s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.352 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.402 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.410 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.407 total time=   0.2s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.406 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.405 total time=   0.2s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.409 total time=   0.1s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.408 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.403 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.409 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.408 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.407 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.409 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.409 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.409 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.409 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.410 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.408 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.413 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.409 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.414 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.410 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.414 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.411 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.410 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.406 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.411 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.406 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.412 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.410 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.411 total time=   0.0s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.347 total time=   0.5s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.359 total time=   0.4s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.357 total time=   0.3s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.363 total time=   0.9s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.344 total time=   0.2s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.399 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.411 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.406 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.416 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.1;, score=-0.399 total time=   0.3s\n",
      "[CV 1/5] END ........alpha=0.15000000000000002;, score=-0.402 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.15000000000000002;, score=-0.413 total time=   0.1s\n",
      "[CV 3/5] END ........alpha=0.15000000000000002;, score=-0.410 total time=   0.2s\n",
      "[CV 4/5] END ........alpha=0.15000000000000002;, score=-0.419 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.15000000000000002;, score=-0.401 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.2;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.2;, score=-0.413 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.2;, score=-0.410 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.2;, score=-0.420 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.2;, score=-0.402 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.25;, score=-0.403 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.25;, score=-0.414 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.25;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END .......................alpha=0.25;, score=-0.420 total time=   0.2s\n",
      "[CV 5/5] END .......................alpha=0.25;, score=-0.402 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.3;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.3;, score=-0.414 total time=   0.2s\n",
      "[CV 3/5] END ........................alpha=0.3;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.3;, score=-0.421 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.3;, score=-0.403 total time=   0.1s\n",
      "[CV 1/5] END ........alpha=0.35000000000000003;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END ........alpha=0.35000000000000003;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.35000000000000003;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........alpha=0.35000000000000003;, score=-0.421 total time=   0.1s\n",
      "[CV 5/5] END ........alpha=0.35000000000000003;, score=-0.403 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.4;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.4;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.4;, score=-0.411 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.4;, score=-0.421 total time=   0.1s\n",
      "[CV 5/5] END ........................alpha=0.4;, score=-0.403 total time=   0.1s\n",
      "[CV 1/5] END .......................alpha=0.45;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.45;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.45;, score=-0.411 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.45;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.45;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.5;, score=-0.404 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.5;, score=-0.414 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.5;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.5;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.5;, score=-0.403 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.55;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .......................alpha=0.55;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END .......................alpha=0.55;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.55;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.55;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6000000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.6000000000000001;, score=-0.415 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.6000000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6000000000000001;, score=-0.421 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6000000000000001;, score=-0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.6500000000000001;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.6500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.6500000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.6500000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.7000000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.7000000000000001;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.7000000000000001;, score=-0.412 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.7000000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7000000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.7500000000000001;, score=-0.405 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.7500000000000001;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.7500000000000001;, score=-0.412 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.7500000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.7500000000000001;, score=-0.404 total time=   0.1s\n",
      "[CV 1/5] END ........................alpha=0.8;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.8;, score=-0.416 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.8;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.8;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.8;, score=-0.405 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.8500000000000001;, score=-0.416 total time=   0.1s\n",
      "[CV 3/5] END .........alpha=0.8500000000000001;, score=-0.413 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.8500000000000001;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.8500000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.9000000000000001;, score=-0.406 total time=   0.1s\n",
      "[CV 2/5] END .........alpha=0.9000000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9000000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9000000000000001;, score=-0.423 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.9000000000000001;, score=-0.405 total time=   0.1s\n",
      "[CV 1/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.9500000000000001;, score=-0.416 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.9500000000000001;, score=-0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.9500000000000001;, score=-0.423 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.9500000000000001;, score=-0.406 total time=   0.0s\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................alpha=0.05;, score=-0.354 total time=   0.2s\n",
      "[CV 2/5] END .......................alpha=0.05;, score=-0.361 total time=   0.3s\n",
      "[CV 3/5] END .......................alpha=0.05;, score=-0.356 total time=   0.2s\n",
      "[CV 4/5] END .......................alpha=0.05;, score=-0.353 total time=   0.2s\n",
      "[CV 5/5] END .......................alpha=0.05;, score=-0.357 total time=   0.2s\n",
      "[CV 1/5] END ........................alpha=0.1;, score=-0.409 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.1;, score=-0.415 total time=   0.1s\n",
      "[CV 3/5] END ........................alpha=0.1;, score=-0.408 total time=   0.1s\n",
      "[CV 4/5] END ........................alpha=0.1;, score=-0.405 total time=   0.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m### LASSO MODEL ###\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m lasso_mod \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m lasso_mod\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     17\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m lasso_mod\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    994\u001b[0m         )\n\u001b[1;32m    995\u001b[0m     )\n\u001b[0;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:859\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    857\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    863\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1084\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1083\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1109\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/daenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    681\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    682\u001b[0m         coef_,\n\u001b[1;32m    683\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         positive,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcd_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    702\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize lists for both sets\n",
    "rmse_lasso_test, r2_lasso_test = [], []\n",
    "rmse_lasso_train, r2_lasso_train = [], []\n",
    "pred_lasso_test, pred_lasso_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = logitvars.iloc[train_index], logitvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### LASSO MODEL ###\n",
    "    lasso_mod = search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = lasso_mod.predict(X_test)\n",
    "    y_pred_train = lasso_mod.predict(X_train)\n",
    "    \n",
    "    pred_lasso_test.append(y_pred_test.mean())\n",
    "    pred_lasso_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_lasso_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_lasso_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_lasso_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_lasso_train.append(r2_score(y_train, y_pred_train))\n",
    "\n",
    "# Quick summary of the averages\n",
    "print(f\"Train RMSE: {np.mean(rmse_lasso_train):.4f} vs Test RMSE: {np.mean(rmse_lasso_test):.4f}\")\n",
    "print(f\"Train R2:   {np.mean(r2_lasso_train):.4f} vs Test R2:   {np.mean(r2_lasso_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ddbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lasso_mod = {\n",
    "        \"predicted train\": pred_lasso_train,\n",
    "        \"r2 train\": r2_lasso_train,\n",
    "        \"rmse train\": rmse_lasso_train,\n",
    "        \"predicted test\": pred_lasso_test,\n",
    "        \"r2 test\": r2_lasso_test,\n",
    "        \"rmse test\": pred_lasso_test\n",
    "    }\n",
    "results_lasso_mod = pd.concat([pd.DataFrame(results_lasso_mod), pd.DataFrame(pd.DataFrame(results_lasso_mod).mean(), columns=[\"Average\"]).T])\n",
    "results_lasso_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10def78a",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7124297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(random_state = 20250224)\n",
    "tune_grid = {\"max_features\": [6, 8, 10, 12], \"min_samples_leaf\": [5, 10, 15]}\n",
    "\n",
    "rf_random = GridSearchCV(\n",
    "    estimator = rfr,\n",
    "    param_grid = tune_grid,\n",
    "    cv = 5,\n",
    "    scoring = \"neg_root_mean_squared_error\",\n",
    "    verbose = 3,\n",
    ")\n",
    "# Built into grid search, it will run on the test set, not on the train set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch out, this takes 10 minutes to run!\n",
    " \n",
    "rmse_rf_test, r2_rf_test = [], []\n",
    "rmse_rf_train, r2_rf_train = [], []\n",
    "pred_rf_test, pred_rf_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = rfvars.iloc[train_index], rfvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### Random Forest Model ###\n",
    "    rf_mod = rf_random.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = rf_mod.predict(X_test)\n",
    "    y_pred_train = rf_mod.predict(X_train)\n",
    "    \n",
    "    pred_rf_test.append(y_pred_test.mean())\n",
    "    pred_rf_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_rf_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_rf_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_rf_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_rf_train.append(r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ee8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_mod = {\n",
    "        \"predicted train\": pred_rf_train,\n",
    "        \"r2 train\": r2_rf_train,\n",
    "        \"rmse train\": rmse_rf_train,\n",
    "        \"predicted test\": pred_rf_test,\n",
    "        \"r2 test\": r2_rf_test,\n",
    "        \"rmse test\": pred_rf_test\n",
    "    }\n",
    "results_rf_mod = pd.concat([pd.DataFrame(results_rf_mod), pd.DataFrame(pd.DataFrame(results_rf_mod).mean(), columns=[\"Average\"]).T])\n",
    "results_rf_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6913ad",
   "metadata": {},
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeRegressor(random_state=1234, criterion=\"squared_error\",max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cart_test, r2_cart_test = [], []\n",
    "rmse_cart_train, r2_cart_train = [], []\n",
    "pred_cart_test, pred_cart_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = rfvars.iloc[train_index], rfvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### Random Forest Model ###\n",
    "    cart_mod = cart.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = rf_mod.predict(X_test)\n",
    "    y_pred_train = rf_mod.predict(X_train)\n",
    "    \n",
    "    pred_cart_test.append(y_pred_test.mean())\n",
    "    pred_cart_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_cart_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_cart_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_cart_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_cart_train.append(r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d378213",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cart_mod = {\n",
    "        \"predicted train\": pred_cart_train,\n",
    "        \"r2 train\": r2_cart_train,\n",
    "        \"rmse train\": rmse_cart_train,\n",
    "        \"predicted test\": pred_cart_test,\n",
    "        \"r2 test\": r2_cart_test,\n",
    "        \"rmse test\": pred_cart_test\n",
    "    }\n",
    "results_cart_mod = pd.concat([pd.DataFrame(results_cart_mod), pd.DataFrame(pd.DataFrame(results_cart_mod).mean(), columns=[\"Average\"]).T])\n",
    "results_cart_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a1942",
   "metadata": {},
   "source": [
    "### BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor(learning_rate=0.1, min_samples_split=20, max_features = 10\n",
    "                                #, n_estimators = 50\n",
    "                               )\n",
    "\n",
    "tune_grid = {\"n_estimators\": [200, 300], \"max_depth\": [5, 10]}\n",
    "\n",
    "gbm_model_cv = GridSearchCV(\n",
    "    gbm,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Flatten categorical_columns and ensure no nested lists\n",
    "# We use a list comprehension to make sure we only grab strings\n",
    "raw_cat_list = engvar3 + [\"balsheet_notfullyear\", \"foreign_management\"]\n",
    "categorical_columns = []\n",
    "for item in raw_cat_list:\n",
    "    if isinstance(item, list):\n",
    "        categorical_columns.extend(item)\n",
    "    else:\n",
    "        categorical_columns.append(item)\n",
    "\n",
    "# 2. Flatten all_vars the same way\n",
    "final_all_vars = []\n",
    "for item in all_vars:\n",
    "    if isinstance(item, list):\n",
    "        final_all_vars.extend(item)\n",
    "    else:\n",
    "        final_all_vars.append(item)\n",
    "\n",
    "# 3. Filter numerical columns based on the flattened lists\n",
    "numerical_columns = [col for col in final_all_vars if col not in categorical_columns]\n",
    "\n",
    "# 4. Redefine Preprocessing\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Now try the fit again\n",
    "gbm_pipe = Pipeline([(\"preprocess\", preprocessing), (\"regressor\", gbm_model_cv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6721a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch out this takes 10 min to run!\n",
    "#\n",
    "r2_gbm_test, r2_gbm_train = [], []\n",
    "rmse_gbm_test, rmse_gbm_train = [], []\n",
    "pred_gbm_test, pred_gbm_train = [], []\n",
    "\n",
    "for train_index, test_index in k.split(firms_df[final_all_vars]):\n",
    "    \n",
    "    X_train, X_test = firms_df[final_all_vars].iloc[train_index], firms_df[final_all_vars].iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # 1. Fit the model\n",
    "    gbm_mod = gbm_pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. Predict for TRAIN and calculate metrics\n",
    "    y_pred_train = gbm_mod.predict(X_train)  # <--- Define this!\n",
    "    pred_gbm_train.append(y_pred_train.mean())\n",
    "    rmse_gbm_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_gbm_train.append(r2_score(y_train, y_pred_train))\n",
    "\n",
    "    # 3. Predict for TEST and calculate metrics\n",
    "    y_pred_test = gbm_mod.predict(X_test)    # <--- Define this!\n",
    "    pred_gbm_test.append(y_pred_test.mean())\n",
    "    rmse_gbm_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_gbm_test.append(r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb54043",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbm_mod = {\n",
    "        \"predicted train\": pred_gbm_train,\n",
    "        \"r2 train\": r2_gbm_train,\n",
    "        \"rmse train\": rmse_gbm_train,\n",
    "        \"predicted test\": pred_gbm_test,\n",
    "        \"r2 test\": r2_gbm_test,\n",
    "        \"rmse test\": pred_gbm_test\n",
    "    }\n",
    "results_gbm_mod = pd.concat([pd.DataFrame(results_gbm_mod), pd.DataFrame(pd.DataFrame(results_gbm_mod).mean(), columns=[\"Average\"]).T])\n",
    "#pd.DataFrame(results_gbm_mod)\n",
    "results_gbm_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb15b4",
   "metadata": {},
   "source": [
    "### GLM model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch out, this takes 10 minutes to run!\n",
    " \n",
    "rmse_glm_test, r2_glm_test = [], []\n",
    "rmse_glm_train, r2_glm_train = [], []\n",
    "pred_glm_test, pred_glm_train = [], []\n",
    "\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for train_index, test_index in k.split(rfvars):\n",
    "    \n",
    "    X_train, X_test = rfvars.iloc[train_index], rfvars.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ### GLM ###\n",
    "    glm_modelx1 = LogisticRegression(\n",
    "    solver = \"newton-cg\", \n",
    "    max_iter = 1000, \n",
    "    penalty = None, \n",
    "    random_state = 1234).fit(X_train, y_train)\n",
    "    #regression_results(y, glm_modelx1.predict(X1))\n",
    "\n",
    "    y_pred_test = glm_modelx1.predict(X_test)\n",
    "    y_pred_train = glm_modelx1.predict(X_train)\n",
    "    \n",
    "    pred_glm_test.append(y_pred_test.mean())\n",
    "    pred_glm_train.append(y_pred_train.mean())\n",
    "\n",
    "    rmse_glm_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    r2_glm_test.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "    rmse_glm_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    r2_glm_train.append(r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glm_modelx1 = {\n",
    "        \"predicted train\": pred_glm_train,\n",
    "        \"r2 train\": r2_glm_train,\n",
    "        \"rmse train\": rmse_glm_train,\n",
    "        \"predicted test\": pred_glm_test,\n",
    "        \"r2 test\": r2_glm_test,\n",
    "        \"rmse test\": pred_glm_test\n",
    "    }\n",
    "results_glm_modelx1 = pd.concat([pd.DataFrame(results_glm_modelx1), pd.DataFrame(pd.DataFrame(results_glm_modelx1).mean(), columns=[\"Average\"]).T])\n",
    "results_glm_modelx1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4922fb",
   "metadata": {},
   "source": [
    "### comparing all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing all models:\n",
    "\n",
    "model_comparison = pd.DataFrame({'model': ['OLS', 'LASSO', \"CART\", 'GBM', 'RF', \"GLM1\"],\n",
    "    'RMSE': [np.mean(rmse_modelx1_train), np.mean(rmse_lasso_train),\n",
    "            np.mean(rmse_cart_train), np.mean(rmse_gbm_train), np.mean(rmse_rf_train),\n",
    "            np.mean(rmse_glm_train)],\n",
    "    \"R2\": [np.mean(r2_modelx1_train), np.mean(r2_lasso_train),\n",
    "            np.mean(r2_cart_train), np.mean(r2_gbm_train), np.mean(r2_rf_train),\n",
    "            np.mean(r2_glm_train)]\n",
    "})\n",
    "\n",
    "print(\"The Random Forest model works best in both RMSE and R2\")\n",
    "model_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
